{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install tqdm\n",
    "# !pip install sklearn\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is dev branch\n",
    "import datetime\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "NUM_TIME_SLOTS = 144\n",
    "NUM_DAYS_IN_DATA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 hours is divided into 144 slots where each slot is 10 mins long\n",
    "def calculateTimeSlot(time,printValue=True):\n",
    "    global NUM_TIME_SLOTS\n",
    "    dateTime = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    timePart = dateTime.time()\n",
    "    timeInMinutes = (timePart.hour * 60) + timePart.minute + (timePart.second/60) + 1\n",
    "    timeSlot = timeInMinutes/10\n",
    "    roundedTimeSlot = math.ceil(timeSlot)\n",
    "    if roundedTimeSlot > NUM_TIME_SLOTS:\n",
    "        roundedTimeSlot -= 1\n",
    "    if printValue==True:\n",
    "        print(f\"time: {time} timeInMinutes: {timeInMinutes} timeSlot: {roundedTimeSlot}\")\n",
    "    return int(roundedTimeSlot)\n",
    "\n",
    "def extractDayOfWeek(time):\n",
    "    d = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    return d.weekday()\n",
    "\n",
    "def extractDate(time):\n",
    "    d = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    return d.date()\n",
    "\n",
    "print(type(extractDate('2019-01-01 00:00:00')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNumberOfPOI(poiArray):\n",
    "    poiCount = 0\n",
    "    for poiEntry in poiArray:\n",
    "        poiEntry = poiEntry + ':'\n",
    "        divisions = poiEntry.split(\":\")\n",
    "        poiCount += int(divisions[1])\n",
    "    return poiCount\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMultipleData(path,fileNamePrefix,headerNames,dataTypes):\n",
    "    global NUM_DAYS_IN_DATA\n",
    "    filesToExplore = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.startswith(fileNamePrefix):\n",
    "            filesToExplore.append(file)\n",
    "            # print(f\"{file} read\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    print(f\"{len(filesToExplore)} files read\")\n",
    "    if fileNamePrefix == 'order':\n",
    "        NUM_DAYS_IN_DATA = len(filesToExplore)\n",
    "    \n",
    "    readData = []\n",
    "    for files in filesToExplore:\n",
    "        fileRead = pd.read_csv(path + files, sep='\\t', names=headerNames,dtype=dataTypes)\n",
    "        readData.append(fileRead)\n",
    "\n",
    "    readData = pd.concat(readData, ignore_index=True)\n",
    "    return readData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now region Data\n",
    "regionData = pd.read_csv('./training_data/cluster_map/cluster_map', sep='\\t', names=['region_hash', 'region_id'],dtype={'region_hash': 'str', 'region_id': 'int'})\n",
    "# print(regionData.head())\n",
    "regionData.to_csv('regionData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read order data\n",
    "dataTypes = {'order_id':'str', 'driver_id':'str', 'passenger_id':'str', 'start_region_hash':'str', 'dest_region_hash':'str', 'price':'double', 'time':'str'}\n",
    "orderDataPath = './training_data/order_data/'\n",
    "orderData = readMultipleData(orderDataPath,'order', ['order_id', 'driver_id', 'passenger_id', 'start_region_hash', 'dest_region_hash', 'price', 'time'], dataTypes)\n",
    "print(\"printing order data\")\n",
    "# print(orderData.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read weather data\n",
    "dataTypes={'time':'str', 'weather':'int', 'temperature':'double', 'PM2.5':'double'}\n",
    "weatherDataPath = './training_data/weather_data/'\n",
    "weatherData = readMultipleData(weatherDataPath,'weather', ['time', 'weather', 'temperature', 'PM2.5'], dataTypes)\n",
    "print(\"printing weather data\")\n",
    "# print(weatherData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherData['time_slot'] = weatherData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "weatherData['date'] = weatherData['time'].apply(extractDate)\n",
    "# weatherData['day_of_week'] = weatherData['time'].apply(extractDayOfWeek)\n",
    "weatherData = weatherData.drop(['temperature','PM2.5','time'], axis=1)\n",
    "print(weatherData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = pd.merge(regionData,orderData, how='left', right_on='start_region_hash', left_on='region_hash')\n",
    "orderData['time_slot'] = orderData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "orderData['day_of_week'] = orderData['time'].apply(extractDayOfWeek)\n",
    "orderData['date'] = orderData['time'].apply(extractDate)\n",
    "orderData = orderData.drop(['passenger_id', 'dest_region_hash','start_region_hash','price'], axis=1)\n",
    "print(orderData.head())\n",
    "# regionData=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedOrderData = pd.merge(weatherData,orderData, how=\"inner\", on=['date','time_slot'])\n",
    "print(mergedOrderData.head())\n",
    "# orderData.to_csv('orderData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData=None\n",
    "orderData = mergedOrderData\n",
    "# orderData.to_csv('mergedOrderData.csv',index=False)\n",
    "# type(orderData['driver_id'][4])==float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = pd.read_csv('mergedOrderData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read POI Data\n",
    "poiDataStr = {\n",
    "    'region_hash':[],\n",
    "    'poi_class':[]\n",
    "}\n",
    "with open('./training_data/poi_data/poi_data','r') as fileToRead:\n",
    "    for line in fileToRead:\n",
    "        line = line.strip()\n",
    "        columns = line.split('\\t')\n",
    "        poiDataStr['region_hash'].append(columns[0])\n",
    "        remData = columns[1:]\n",
    "        poiDataStr['poi_class'].append(remData)\n",
    "        \n",
    "poiData = pd.DataFrame(poiDataStr,columns=['region_hash','poi_class'])\n",
    "poiData['poi_count'] = poiData['poi_class'].apply(extractNumberOfPOI)\n",
    "poiData = pd.merge(regionData,poiData, how='inner', on='region_hash')\n",
    "poiData = poiData.drop(['region_hash'], axis=1)\n",
    "poiData = poiData.drop(['poi_class'], axis=1)\n",
    "print(poiData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = pd.merge(orderData,poiData, how=\"inner\", on='region_id')\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mergedDataCSV)\n",
    "orderData['requests'] = 1\n",
    "# print(orderData.head())\n",
    "groupedMergedData = orderData.groupby(['region_id','time_slot','day_of_week','weather','poi_count'])['requests'].agg('sum').reset_index()\n",
    "# groupedMergedData = groupedMergedData.drop(['date','region_hash','order_id','driver_id','time'], axis=1)\n",
    "orderData = pd.merge(orderData,groupedMergedData, how='left' , on=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = orderData.drop([\"requests_x\"], axis=1)\n",
    "orderData = orderData.rename(columns={\"requests_y\": \"requests\"})\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData['temp'] = 1\n",
    "orderData['answers'] = orderData['temp'].where(orderData['driver_id'].notnull(), 0)\n",
    "orderData = orderData.drop(['temp'], axis=1)\n",
    "groupedMergedData = orderData.groupby(['region_id','time_slot','day_of_week','weather','poi_count'])['answers'].agg('sum').reset_index()\n",
    "orderData = pd.merge(orderData,groupedMergedData, how='left' , on=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "print(orderData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = orderData.drop([\"answers_x\"], axis=1)\n",
    "orderData = orderData.rename(columns={\"answers_y\": \"answers\"})\n",
    "orderData.to_csv('mergedOrderData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = pd.read_csv('mergedOrderData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          weather  time_slot        date                       region_hash   \n",
      "0               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a  \\\n",
      "1               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "...           ...        ...         ...                               ...   \n",
      "12222999        2        141  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223000        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223001        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223002        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223003        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "\n",
      "          region_id                          order_id   \n",
      "0                 1  df1dc94f51fec68d3116e4b6bd8480a9  \\\n",
      "1                 1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2                 1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3                 1  74d98ad919a078a4c084098e2fdef219   \n",
      "4                 1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "...             ...                               ...   \n",
      "12222999         62  31ca3cf08e2886eed36e9377933c2990   \n",
      "12223000         62  1068450007355a22907fded661ce2939   \n",
      "12223001         62  9555828a2e7ac1e6e2197e20bde65f8b   \n",
      "12223002         62  1068450007355a22907fded661ce2939   \n",
      "12223003         62  9555828a2e7ac1e6e2197e20bde65f8b   \n",
      "\n",
      "                                 driver_id                 time  day_of_week   \n",
      "0         9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4  \\\n",
      "1         3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2         448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3         ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4         424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "...                                    ...                  ...          ...   \n",
      "12222999                               NaN  2016-01-21 23:20:05            3   \n",
      "12223000                               NaN  2016-01-21 23:32:52            3   \n",
      "12223001                               NaN  2016-01-21 23:36:52            3   \n",
      "12223002                               NaN  2016-01-21 23:32:52            3   \n",
      "12223003                               NaN  2016-01-21 23:36:52            3   \n",
      "\n",
      "          poi_count  requests  answers  supply_demand  \n",
      "0            653376       330      314             16  \n",
      "1            653376       330      314             16  \n",
      "2            653376       330      314             16  \n",
      "3            653376       330      314             16  \n",
      "4            653376       330      314             16  \n",
      "...             ...       ...      ...            ...  \n",
      "12222999       2988         2        0              2  \n",
      "12223000       2988         4        0              4  \n",
      "12223001       2988         4        0              4  \n",
      "12223002       2988         4        0              4  \n",
      "12223003       2988         4        0              4  \n",
      "\n",
      "[12223004 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "orderData['supply_demand'] = orderData['requests'] - orderData['answers']\n",
    "print(orderData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=5, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=5, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply model here\n",
    "AImodel = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=0)\n",
    "X = orderData[['region_id','time_slot','day_of_week','weather','poi_count']]\n",
    "Y = orderData['supply_demand']\n",
    "AImodel.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.65673643]\n",
      "0.4313027409787012\n"
     ]
    }
   ],
   "source": [
    "tempData = pd.DataFrame([[1,5,3,7,20000]],columns=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "# tempData = pd.DataFrame([[1,5,3,7,20000]],columns=['region_id','time_slot'])\n",
    "print(AImodel.predict(tempData))\n",
    "mse = mean_squared_error([28], AImodel.predict(tempData))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make rolling window function\n",
    "def rollTheWindow(data,windowSize):\n",
    "    datasetLength = len(data)\n",
    "    listOfPredictions = []\n",
    "    numberOfWindows = datasetLength//windowSize\n",
    "    for i in range(numberOfWindows):\n",
    "        rollingWindow = []\n",
    "        lowerLimit = i\n",
    "        upperLimit = i+windowSize\n",
    "        rollingWindow.append(data[lowerLimit:upperLimit])\n",
    "        rollingWindow = pd.concat(rollingWindow)\n",
    "        X_WINDOW_INPUT = rollingWindow[['region_id','time_slot','day_of_week','weather','poi_count']]\n",
    "        Y_WINDOW_OUTPUT = rollingWindow['supply_demand']\n",
    "        currentPrediction = AImodel.predict(X_WINDOW_INPUT)\n",
    "        meanSqError = mean_squared_error(Y_WINDOW_OUTPUT, currentPrediction)\n",
    "        print(f\"Prediction for window [{lowerLimit},{upperLimit}]={currentPrediction} MSE={meanSqError}\")\n",
    "        predictionTuple = (lowerLimit,upperLimit,currentPrediction,meanSqError)\n",
    "        listOfPredictions.append(predictionTuple)\n",
    "        i = upperLimit + 1\n",
    "    return listOfPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for window [0,1]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [1,2]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [2,3]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [3,4]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [4,5]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [5,6]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [6,7]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [7,8]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [8,9]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [9,10]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [10,11]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [11,12]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [12,13]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [13,14]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [14,15]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [15,16]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [16,17]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [17,18]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [18,19]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [19,20]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [20,21]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [21,22]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [22,23]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [23,24]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [24,25]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [25,26]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [26,27]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [27,28]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [28,29]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [29,30]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [30,31]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [31,32]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [32,33]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [33,34]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [34,35]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [35,36]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [36,37]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [37,38]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [38,39]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [39,40]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [40,41]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [41,42]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [42,43]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [43,44]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [44,45]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [45,46]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [46,47]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [47,48]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [48,49]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [49,50]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [50,51]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [51,52]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [52,53]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [53,54]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [54,55]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [55,56]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [56,57]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [57,58]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [58,59]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [59,60]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [60,61]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [61,62]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [62,63]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [63,64]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [64,65]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [65,66]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [66,67]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [67,68]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [68,69]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [69,70]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [70,71]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [71,72]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [72,73]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [73,74]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [74,75]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [75,76]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [76,77]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [77,78]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [78,79]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [79,80]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [80,81]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [81,82]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [82,83]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [83,84]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [84,85]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [85,86]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [86,87]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [87,88]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [88,89]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [89,90]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [90,91]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [91,92]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [92,93]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [93,94]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [94,95]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [95,96]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [96,97]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [97,98]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [98,99]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [99,100]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [100,101]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [101,102]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [102,103]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [103,104]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [104,105]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [105,106]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [106,107]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [107,108]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [108,109]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [109,110]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [110,111]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [111,112]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [112,113]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [113,114]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [114,115]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [115,116]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [116,117]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [117,118]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [118,119]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [119,120]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [120,121]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [121,122]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [122,123]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [123,124]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [124,125]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [125,126]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [126,127]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [127,128]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [128,129]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [129,130]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [130,131]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [131,132]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [132,133]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [133,134]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [134,135]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [135,136]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [136,137]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [137,138]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [138,139]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [139,140]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [140,141]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [141,142]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [142,143]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [143,144]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [144,145]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [145,146]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [146,147]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [147,148]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [148,149]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [149,150]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [150,151]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [151,152]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [152,153]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [153,154]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [154,155]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [155,156]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [156,157]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [157,158]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [158,159]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [159,160]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [160,161]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [161,162]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [162,163]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [163,164]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [164,165]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [165,166]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [166,167]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [167,168]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [168,169]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [169,170]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [170,171]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [171,172]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [172,173]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [173,174]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [174,175]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [175,176]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [176,177]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [177,178]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [178,179]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [179,180]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [180,181]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [181,182]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [182,183]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [183,184]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [184,185]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [185,186]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [186,187]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [187,188]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [188,189]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [189,190]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [190,191]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [191,192]=[124.21251258] MSE=11709.947878351923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rollTheWindow(orderData,\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[29], line 14\u001b[0m, in \u001b[0;36mrollTheWindow\u001b[1;34m(data, windowSize)\u001b[0m\n\u001b[0;32m     12\u001b[0m X_WINDOW_INPUT \u001b[39m=\u001b[39m rollingWindow[[\u001b[39m'\u001b[39m\u001b[39mregion_id\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtime_slot\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mday_of_week\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mweather\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mpoi_count\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     13\u001b[0m Y_WINDOW_OUTPUT \u001b[39m=\u001b[39m rollingWindow[\u001b[39m'\u001b[39m\u001b[39msupply_demand\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m currentPrediction \u001b[39m=\u001b[39m AImodel\u001b[39m.\u001b[39;49mpredict(X_WINDOW_INPUT)\n\u001b[0;32m     15\u001b[0m meanSqError \u001b[39m=\u001b[39m mean_squared_error(Y_WINDOW_OUTPUT, currentPrediction)\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrediction for window [\u001b[39m\u001b[39m{\u001b[39;00mlowerLimit\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mupperLimit\u001b[39m}\u001b[39;00m\u001b[39m]=\u001b[39m\u001b[39m{\u001b[39;00mcurrentPrediction\u001b[39m}\u001b[39;00m\u001b[39m MSE=\u001b[39m\u001b[39m{\u001b[39;00mmeanSqError\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:994\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[39m# Parallel loop\u001b[39;00m\n\u001b[0;32m    993\u001b[0m lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[1;32m--> 994\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, require\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msharedmem\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\n\u001b[0;32m    995\u001b[0m     delayed(_accumulate_prediction)(e\u001b[39m.\u001b[39;49mpredict, X, [y_hat], lock)\n\u001b[0;32m    996\u001b[0m     \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[0;32m    997\u001b[0m )\n\u001b[0;32m    999\u001b[0m y_hat \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_)\n\u001b[0;32m   1001\u001b[0m \u001b[39mreturn\u001b[39;00m y_hat\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:650\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[0;32m    644\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[39m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \n\u001b[0;32m    647\u001b[0m \u001b[39m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[39m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 650\u001b[0m     prediction \u001b[39m=\u001b[39m predict(X, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    651\u001b[0m     \u001b[39mwith\u001b[39;00m lock:\n\u001b[0;32m    652\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:427\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    425\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    426\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[1;32m--> 427\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m    428\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    430\u001b[0m \u001b[39m# Classification\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rollTheWindow(orderData,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to calculate gap(i,j) = req(i,j) - supply(i,j)\n",
    "# # req(i,j) is for region i and timeslot j \n",
    "# # ith region will be from from start_region_hash and jth timeslot will be calculated from time\n",
    "# def getRegionID(regionHash):\n",
    "#     regionID = -1\n",
    "#     for i in range(len(regionData)):\n",
    "#         if regionHash == regionData['region_hash'][i]:\n",
    "#             regionID = regionData['region_id'][i]\n",
    "#     return regionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergedData = None # here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop order_id, driver_id, passenger_id, dest_region_hash\n",
    "# mergedData = orderData.drop(['order_id', 'passenger_id', 'dest_region_hash'], axis=1)\n",
    "# print(\"dropped order_id, passenger_id, dest_region_hash\")\n",
    "#  merge order data with region data on start_region_hash with region_hash\n",
    "# mergedData = pd.merge(regionData,mergedData, how='left', right_on='start_region_hash', left_on='region_hash')\n",
    "# print(\"merged order data and region data based on region\")\n",
    "\n",
    "# mergedData = mergedData.drop(['region_hash','start_region_hash'], axis=1)\n",
    "# print(\"dropped region_hash, start_region_hash\")\n",
    "# # reduce time to time slot and update time column\n",
    "# mergedData['time'] = mergedData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "# print(\"reduced time to time slot 1 to 144\")\n",
    "# rename time to time_slot\n",
    "# mergedData.rename(columns={'time':'time_slot'}, inplace=True)\n",
    "# # append column for day of week into mergedData\n",
    "# mergedData['day_of_week'] = orderData['time'].apply(extractDayOfWeek)\n",
    "# print(\"appended day_of_week column to data\")\n",
    "# now we have mergedData with region_id, price, time, day_of_week\n",
    "# print(\"printing merged data\")\n",
    "# print(mergedData)\n",
    "\n",
    "# writing to mergedData.csv for quick access\n",
    "# orderData.to_csv('mergedData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mergedData.csv\n",
    "# mergedDataCSV = pd.read_csv('mergedData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mergedDataCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to get req(i,j) we can do that by counting the number of orders for region i and timeslot j\n",
    "# def getRequest(i,j): # i is region id and j is timeslot\n",
    "#     global orderData\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "#     requests = 0\n",
    "#     for row in range(len(orderData)):\n",
    "#         currentRegionID = getRegionID(orderData['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(orderData['time'][row],False)\n",
    "#         if currentRegionID == i and currentTimeSlot == j:\n",
    "#             requests += 1\n",
    "#         progressBarInit.update(1)\n",
    "#     progressBarInit.close()\n",
    "#     return requests\n",
    "\n",
    "# print(\"Printing request for 1st region and 1st timeslot\")\n",
    "# print(getRequest(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def dateToIndex(date):\n",
    "# #     index = 0\n",
    "    \n",
    "# #     return index\n",
    "\n",
    "# def getAllRequestAndSupply(): # need to filter by date \n",
    "#     global orderData\n",
    "#     global regionData\n",
    "#     global NUM_TIME_SLOTS\n",
    "#     global NUM_DAYS_IN_DATA\n",
    "#     numberOfRegions = len(regionData)\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "#     # 3D requests array requests[i][j][k] is number of requests --> date i ,region j, timeslot k\n",
    "#     # requests = [[[0 for k in range(NUM_TIME_SLOTS)] for j in range(numberOfRegions)] for i in range(NUM_DAYS_IN_DATA)]\n",
    "#     # supply = [[[0 for k in range(NUM_TIME_SLOTS)] for j in range(numberOfRegions)] for i in range(NUM_DAYS_IN_DATA)]\n",
    "#     requests = [[0 for j in range(NUM_TIME_SLOTS)] for i in range(numberOfRegions)]\n",
    "#     supply = [[0 for j in range(NUM_TIME_SLOTS)] for i in range(numberOfRegions)]\n",
    "#     for row in range(len(orderData)):\n",
    "#         currentRegionID = getRegionID(orderData['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(orderData['time'][row],False)\n",
    "#         # date = orderData['time'][row].split(' ')[0]\n",
    "        \n",
    "#         if currentRegionID < 0:\n",
    "#             print(f\"Region not found for {orderData['start_region_hash'][row]}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot < 0:\n",
    "#             print(f\"Time slot not found for {orderData['time'][row]}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentRegionID > numberOfRegions:\n",
    "#             print(f\"Region id {currentRegionID} is greater than number of regions {numberOfRegions}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot > NUM_TIME_SLOTS:\n",
    "#             print(f\"Time slot {currentTimeSlot} is greater than number of time slots {NUM_TIME_SLOTS}\")\n",
    "#             print(f\"Time: {orderData['time'][row]}\")\n",
    "#             print(f\"Row: {row}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot == 0:\n",
    "#             print(f\"Time slot is 0 for {orderData['time'][row]}\")\n",
    "#             print(f\"Row: {row}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         # requests[currentDate][currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         requests[currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         if type(orderData['driver_id'][row]) == str:\n",
    "#             supply[currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#             # supply[currentDate][currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         progressBarInit.update(1)\n",
    "#     progressBarInit.close()\n",
    "#     return (requests,supply)\n",
    "\n",
    "# print(\"Printing request and supply regions d(i) and timeslots t(j)\")\n",
    "# (request,supply) = getAllRequestAndSupply()\n",
    "# print(request)\n",
    "# print(supply) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npRequest = np.array(request)\n",
    "# npSupply = np.array(supply)\n",
    "# np.savetxt('request.csv', npRequest, delimiter=',')\n",
    "# np.savetxt('supply.csv', npSupply, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to get req(i,j) we can do that by counting the number of orders for region i and timeslot j\n",
    "# # concurrentI =0\n",
    "# # concurrentJ =0\n",
    "# def getRequestMulti(data, i, j,lowerIndex,upperIndex):\n",
    "#     # (orderData, i, j,lowerIndex,upperIndex) = arguments\n",
    "#     numberOfIterations = upperIndex - lowerIndex\n",
    "#     currentPID = mp.current_process()._identity[0]-1\n",
    "#     # logging.info(f\"process {currentPID}\")\n",
    "#     print(f\"Number of lines of data: {numberOfIterations} for process {currentPID}\")\n",
    "#     # progressBarInit = tqdm(total=numberOfIterations, desc=f\"Calculating requests {currentPID}\", unit=\" lines\")\n",
    "#     lowerIndex = lowerIndex[currentPID]\n",
    "#     upperIndex = upperIndex[currentPID]\n",
    "#     requests = 0\n",
    "#     for row in range(lowerIndex,upperIndex):\n",
    "#         currentRegionID = getRegionID(data['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(data['time'][row],False)\n",
    "#         if currentRegionID == i and currentTimeSlot == j:\n",
    "#             requests += 1\n",
    "#         # progressBarInit.update(1)\n",
    "#     # progressBarInit.close()\n",
    "#     return requests\n",
    "\n",
    "# def getRequestHelper(i,j): # i is region id and j is timeslot\n",
    "#     global orderData\n",
    "#     # global concurrentI\n",
    "#     # global concurrentJ\n",
    "#     # concurrentJ = j\n",
    "#     # concurrentI = i\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     # logging.basicConfig(level=logging.INFO,filename='worker.log', filemode='w')\n",
    "#     # console_handler = logging.StreamHandler()\n",
    "#     # logging.getLogger().addHandler(console_handler)\n",
    "#     # print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     # progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "    \n",
    "#     numberOfProcessesToRun = mp.cpu_count()\n",
    "#     print(f\"CPUs: {numberOfProcessesToRun}\")\n",
    "#     multiProcessingPool = mp.Pool(numberOfProcessesToRun)\n",
    "#     upperIndex = []\n",
    "#     lowerIndex = []\n",
    "#     for i in range(numberOfProcessesToRun):\n",
    "#         lowerval = i*numberOfIterations//numberOfProcessesToRun\n",
    "#         upperVal = (i+1)*numberOfIterations//numberOfProcessesToRun\n",
    "#         lowerIndex.append(lowerval)\n",
    "#         upperIndex.append(upperVal)\n",
    "#     print(\"Here\")\n",
    "#     # argumentsToPass = (orderData, i, j,lowerIndex, upperIndex)\n",
    "#     requests = multiProcessingPool.starmap(getRequestMulti, [(orderData, i, j,lowerIndex, upperIndex)])\n",
    "#     requests = sum(requests)\n",
    "#     multiProcessingPool.close()\n",
    "#     multiProcessingPool.join()\n",
    "#     return requests\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Printing request for 1st region and 1st timeslot\")\n",
    "# print(getRequestHelper(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
