{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is dev branch\n",
    "import datetime\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "\n",
    "NUM_TIME_SLOTS = 144\n",
    "NUM_DAYS_IN_DATA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMultipleData(path,fileNamePrefix,headerNames,dataTypes):\n",
    "    global NUM_DAYS_IN_DATA\n",
    "    filesToExplore = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.startswith(fileNamePrefix):\n",
    "            filesToExplore.append(file)\n",
    "            # print(f\"{file} read\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    print(f\"{len(filesToExplore)} files read\")\n",
    "    if fileNamePrefix == 'order':\n",
    "        NUM_DAYS_IN_DATA = len(filesToExplore)\n",
    "    \n",
    "    readData = []\n",
    "    for files in filesToExplore:\n",
    "        fileRead = pd.read_csv(path + files, sep='\\t', names=headerNames,dtype=dataTypes)\n",
    "        readData.append(fileRead)\n",
    "\n",
    "    readData = pd.concat(readData, ignore_index=True)\n",
    "    return readData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        region_hash  region_id\n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1\n",
      "1  f2c8c4bb99e6377d21de71275afd6cd2          2\n",
      "2  58c7a4888306d8ff3a641d1c0feccbe3          3\n",
      "3  b26a240205c852804ff8758628c0a86a          4\n",
      "4  4b9e4cf2fbdc8281b8a1f9f12b80ce4d          5\n"
     ]
    }
   ],
   "source": [
    "# now region Data\n",
    "regionData = pd.read_csv('./training_data/cluster_map/cluster_map', sep='\\t', names=['region_hash', 'region_id'],dtype={'region_hash': 'str', 'region_id': 'int'})\n",
    "print(regionData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 files read\n",
      "printing order data\n",
      "                           order_id                         driver_id  \\\n",
      "0  97ebd0c6680f7c0535dbfdead6e51b4b  dd65fa250fca2833a3a8c16d2cf0457c   \n",
      "1  92c3ac9251cc9b5aab90b114a1e363be  c077e0297639edcb1df6189e8cda2c3d   \n",
      "2  abeefc3e2aec952468e2fd42a1649640  86dbc1b68de435957c61b5a523854b69   \n",
      "3  cb31d0be64cda3cc66b46617bf49a05c  4fadfa6eeaa694742de036dddf02b0c4   \n",
      "4  139d492189ae5a933122c098f63252b3                               NaN   \n",
      "\n",
      "                       passenger_id                 start_region_hash  \\\n",
      "0  ed180d7daf639d936f1aeae4f7fb482f  4725c39a5e5f4c188d382da3910b3f3f   \n",
      "1  191a180f0a262aff3267775c4fac8972  82cc4851f9e4faa4e54309f8bb73fd7c   \n",
      "2  7029e813bb3de8cc73a8615e2785070c  fff4e8465d1e12621bc361276b6217cf   \n",
      "3  21dc133ac68e4c07803d1c2f48988a83  4b7f6f4e2bf237b6cc58f57142bea5c0   \n",
      "4  26963cc76da2d8450d8f23fc357db987  fc34648599753c9e74ab238e9a4a07ad   \n",
      "\n",
      "                   dest_region_hash  price                 time  \n",
      "0  3e12208dd0be281c92a6ab57d9a6fb32   24.0  2016-01-01 13:37:23  \n",
      "1  b05379ac3f9b7d99370d443cfd5dcc28    2.0  2016-01-01 09:47:54  \n",
      "2  fff4e8465d1e12621bc361276b6217cf    9.0  2016-01-01 18:24:02  \n",
      "3  4b7f6f4e2bf237b6cc58f57142bea5c0   11.0  2016-01-01 22:13:27  \n",
      "4  87285a66236346350541b8815c5fae94    4.0  2016-01-01 17:00:06  \n",
      "21 files read\n",
      "printing weather data\n",
      "                  time  weather  temperature  PM2.5\n",
      "0  2016-01-01 00:00:28        1          4.0  177.0\n",
      "1  2016-01-01 00:05:24        1          3.0  177.0\n",
      "2  2016-01-01 00:10:08        1          3.0  177.0\n",
      "3  2016-01-01 00:15:27        1          3.0  177.0\n",
      "4  2016-01-01 00:20:06        1          3.0  177.0\n"
     ]
    }
   ],
   "source": [
    "# read order data\n",
    "dataTypes = {'order_id':'str', 'driver_id':'str', 'passenger_id':'str', 'start_region_hash':'str', 'dest_region_hash':'str', 'price':'double', 'time':'str'}\n",
    "orderDataPath = './training_data/order_data/'\n",
    "orderData = readMultipleData(orderDataPath,'order', ['order_id', 'driver_id', 'passenger_id', 'start_region_hash', 'dest_region_hash', 'price', 'time'], dataTypes)\n",
    "print(\"printing order data\")\n",
    "print(orderData.head())\n",
    "\n",
    "# read weather data\n",
    "dataTypes={'time':'str', 'weather':'int', 'temperature':'double', 'PM2.5':'double'}\n",
    "weatherDataPath = './training_data/weather_data/'\n",
    "weatherData = readMultipleData(weatherDataPath,'weather', ['time', 'weather', 'temperature', 'PM2.5'], dataTypes)\n",
    "print(\"printing weather data\")\n",
    "print(weatherData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        time  weather  temperature  PM2.5  \\\n",
      "0        2016-01-01 13:37:23      NaN          NaN    NaN   \n",
      "1        2016-01-01 09:47:54      NaN          NaN    NaN   \n",
      "2        2016-01-01 18:24:02      NaN          NaN    NaN   \n",
      "3        2016-01-01 22:13:27      NaN          NaN    NaN   \n",
      "4        2016-01-01 17:00:06      NaN          NaN    NaN   \n",
      "...                      ...      ...          ...    ...   \n",
      "8540609  2016-01-21 20:14:37      NaN          NaN    NaN   \n",
      "8540610  2016-01-21 18:32:09      NaN          NaN    NaN   \n",
      "8540611  2016-01-21 18:11:38      NaN          NaN    NaN   \n",
      "8540612  2016-01-21 18:43:55      NaN          NaN    NaN   \n",
      "8540613  2016-01-21 16:54:37      NaN          NaN    NaN   \n",
      "\n",
      "                                 order_id                         driver_id  \\\n",
      "0        97ebd0c6680f7c0535dbfdead6e51b4b  dd65fa250fca2833a3a8c16d2cf0457c   \n",
      "1        92c3ac9251cc9b5aab90b114a1e363be  c077e0297639edcb1df6189e8cda2c3d   \n",
      "2        abeefc3e2aec952468e2fd42a1649640  86dbc1b68de435957c61b5a523854b69   \n",
      "3        cb31d0be64cda3cc66b46617bf49a05c  4fadfa6eeaa694742de036dddf02b0c4   \n",
      "4        139d492189ae5a933122c098f63252b3                               NaN   \n",
      "...                                   ...                               ...   \n",
      "8540609  cafb9e232939a35864828106a9eb29de  41b1420d7eca93cae483a3cc512a3c8e   \n",
      "8540610  5cb3d303c27e40a1c299db008a12c05e  613ab06307b1a4e280f3790e8b70a465   \n",
      "8540611  054490fd30b954d5d270fdccc4640d65  88c1497b0403e38f15c9d2776a7e3822   \n",
      "8540612  361f6ea3eb5436ae5e0c16c12b9ec645  82d199a4dd2cfefb2f5e4b417e27b1d8   \n",
      "8540613  3673198e2e01435aaef317a4e43cf1fc                               NaN   \n",
      "\n",
      "                             passenger_id                 start_region_hash  \\\n",
      "0        ed180d7daf639d936f1aeae4f7fb482f  4725c39a5e5f4c188d382da3910b3f3f   \n",
      "1        191a180f0a262aff3267775c4fac8972  82cc4851f9e4faa4e54309f8bb73fd7c   \n",
      "2        7029e813bb3de8cc73a8615e2785070c  fff4e8465d1e12621bc361276b6217cf   \n",
      "3        21dc133ac68e4c07803d1c2f48988a83  4b7f6f4e2bf237b6cc58f57142bea5c0   \n",
      "4        26963cc76da2d8450d8f23fc357db987  fc34648599753c9e74ab238e9a4a07ad   \n",
      "...                                   ...                               ...   \n",
      "8540609  8624faec3daacfb8c25ab32fc24138ac  4725c39a5e5f4c188d382da3910b3f3f   \n",
      "8540610  9a03b3b33c60b2fa437a76ac97a5412f  b05379ac3f9b7d99370d443cfd5dcc28   \n",
      "8540611  3d3354e5cf6d6d7d5a62db0a78d69e77  2407d482f0ffa22a947068f2551fe62c   \n",
      "8540612  0ae5e59b712786b3c3796da8c8716349  d05052b4bda7662a084f235e880f50fa   \n",
      "8540613  d3efd8d49011077144a3c5913afc8878  2407d482f0ffa22a947068f2551fe62c   \n",
      "\n",
      "                         dest_region_hash  price  \n",
      "0        3e12208dd0be281c92a6ab57d9a6fb32   24.0  \n",
      "1        b05379ac3f9b7d99370d443cfd5dcc28    2.0  \n",
      "2        fff4e8465d1e12621bc361276b6217cf    9.0  \n",
      "3        4b7f6f4e2bf237b6cc58f57142bea5c0   11.0  \n",
      "4        87285a66236346350541b8815c5fae94    4.0  \n",
      "...                                   ...    ...  \n",
      "8540609  929ec6c160e6f52c20a4217c7978f681   13.0  \n",
      "8540610  38d5ad2d22b61109fd8e7b43cd0e8901   16.0  \n",
      "8540611  62afaf3288e236b389af9cfdc5206415   27.9  \n",
      "8540612  90c5a34f06ac86aee0fd70e2adce7d8a   11.0  \n",
      "8540613  62afaf3288e236b389af9cfdc5206415   18.9  \n",
      "\n",
      "[8540614 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(weatherData)\n",
    "orderData = pd.merge(weatherData,orderData, how=\"right\", on=\"time\")\n",
    "print(orderData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(orderData['driver_id'][4])==float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing poi data\n",
      "                        region_hash  \\\n",
      "0  74c1c25f4b283fa74a5514307b0d0278   \n",
      "1  08f5b445ec6b29deba62e6fd8b0325a6   \n",
      "2  4b7f6f4e2bf237b6cc58f57142bea5c0   \n",
      "3  a814069db8d32f0fa6e188f41059c6e1   \n",
      "4  8316146a6f78cc6d9f113f0390859417   \n",
      "\n",
      "                                           poi_class  \n",
      "0  [1#11:2241, 1#10:249, 24:1245, 25:3652, 20:334...  \n",
      "1  [20#7:249, 20#5:83, 2#7:166, 20#2:747, 20#1:99...  \n",
      "2  [4#16:249, 24:913, 25:332, 20:4316, 22:415, 4:...  \n",
      "3  [1#11:498, 24:332, 25:581, 20:5810, 22:2407, 4...  \n",
      "4  [20#7:581, 20#5:83, 20#4:415, 20#2:166, 20#1:6...  \n",
      "Printing poi data line 1\n",
      "region_hash: 74c1c25f4b283fa74a5514307b0d0278 poi_class: ['1#11:2241', '1#10:249', '24:1245', '25:3652', '20:33449', '22:2324', '23:913', '4:13031', '8:166', '5#4:83', '5#3:3569', '5#2:83', '5#1:4731', '8#2:8798', '8#3:5229', '8#1:664', '8#4:7387', '8#5:83', '1#3:498', '1#2:2822', '1#1:415', '1#7:166', '1#6:83', '1#5:12367', '1#4:249', '1#9:166', '1#8:4316', '14#10:664', '7:6640', '15#7:1411', '15#6:5644', '15#4:249', '15#3:11537', '15#2:4150', '4#8:747', '4#9:2988', '4#6:913', '4#7:1743', '4#4:166', '4#5:4814', '4#2:1328', '4#3:1743', '4#1:664', '16#1:83', '16#2:332', '16#3:332', '16#4:7968', '17#1:249', '16#9:332', '17#3:498', '17#2:12201', '17#5:20999', '17#4:3569', '11#8:36188', '13#8:1660', '11#3:6640', '11#2:7221', '11#1:1992', '11#7:2490', '11#6:18924', '11#5:2822', '11#4:30544', '19#3:27722', '19#2:1245', '19#1:1826', '19#4:581', '14#6:1909', '14#7:1909', '14#2:83', '14#3:1245', '6:8466', '14#8:83', '14#9:83', '4#10:4067', '4#11:3569', '4#12:83', '4#13:7387', '4#14:2656', '4#16:664', '4#17:4150', '4#18:4648', '3#1:3652', '3#3:166', '3#2:166', '11:10956', '15:6059', '14:4399', '17:2988', '16:7636', '19:55859', '6#1:1826', '6#2:664', '6#4:830', '2#12:4648', '2#13:249', '2#10:2490', '2#11:1826', '20#7:11952', '20#6:830', '20#5:5561', '20#4:11703', '20#2:6557', '20#1:8217', '16#12:3818', '16#10:15521', '16#11:9711', '20#8:118690', '23#1:498', '23#2:83', '23#3:498', '23#4:249', '23#5:996', '23#6:249', '22#1:498', '22#3:83', '22#2:2324', '22#5:913', '22#4:1328', '25#8:1909', '25#9:6142', '25#3:581', '25#6:415', '25#7:4980', '25#5:249', '1:4482', '5:249', '24#3:166', '24#2:5727', '24#1:133713', '13#4:19173', '2#8:166', '2#4:249', '2#5:1079', '2#6:1245', '2#7:1826', '2#1:83', '2#2:9213', '2#3:415']\n"
     ]
    }
   ],
   "source": [
    "# read POI Data\n",
    "poiDataStr = {\n",
    "    'region_hash':[],\n",
    "    'poi_class':[]\n",
    "}\n",
    "with open('./training_data/poi_data/poi_data','r') as fileToRead:\n",
    "    for line in fileToRead:\n",
    "        line = line.strip()\n",
    "        columns = line.split('\\t')\n",
    "        poiDataStr['region_hash'].append(columns[0])\n",
    "        remData = columns[1:]\n",
    "        poiDataStr['poi_class'].append(remData)\n",
    "        \n",
    "poiData = pd.DataFrame(poiDataStr,columns=['region_hash','poi_class'])\n",
    "print(\"printing poi data\")\n",
    "print(poiData.head())\n",
    "print(\"Printing poi data line 1\")\n",
    "print(f\"region_hash: {poiData['region_hash'][0]} poi_class: {poiData['poi_class'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orderData = pd.merge(orderData,poiData, how=\"outer\",right=\"region_hash\",left=\"start_region_hash\")\n",
    "# print(orderData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing region id for 1st row\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# now to calculate gap(i,j) = req(i,j) - supply(i,j)\n",
    "# req(i,j) is for region i and timeslot j \n",
    "# ith region will be from from start_region_hash and jth timeslot will be calculated from time\n",
    "def getRegionID(regionHash):\n",
    "    regionID = -1\n",
    "    for i in range(len(regionData)):\n",
    "        if regionHash == regionData['region_hash'][i]:\n",
    "            regionID = regionData['region_id'][i]\n",
    "    return regionID\n",
    "\n",
    "print(\"Printing region id for 1st row\")\n",
    "print(getRegionID(regionData['region_hash'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing time slot for 1st row\n",
      "time: 2016-01-01 23:54:27 timeInMinutes: 1435.45 timeSlot: 144\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "# 24 hours is divided into 144 slots where each slot is 10 mins long\n",
    "def calculateTimeSlot(time,printValue=True):\n",
    "    global NUM_TIME_SLOTS\n",
    "    dateTime = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    timePart = dateTime.time()\n",
    "    timeInMinutes = (timePart.hour * 60) + timePart.minute + (timePart.second/60) + 1\n",
    "    timeSlot = timeInMinutes/10\n",
    "    roundedTimeSlot = math.ceil(timeSlot)\n",
    "    if roundedTimeSlot > NUM_TIME_SLOTS:\n",
    "        roundedTimeSlot -= 1\n",
    "    if printValue==True:\n",
    "        print(f\"time: {time} timeInMinutes: {timeInMinutes} timeSlot: {roundedTimeSlot}\")\n",
    "    return int(roundedTimeSlot)\n",
    "\n",
    "print(\"Printing time slot for 1st row\")\n",
    "print(calculateTimeSlot(orderData['time'][627]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractDayOfWeek(time):\n",
    "    dateTime = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    return dateTime.weekday()\n",
    "\n",
    "extractDayOfWeek(orderData['time'][627])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped order_id, passenger_id, dest_region_hash\n",
      "merged order data and region data based on region\n",
      "dropped region_hash, start_region_hash\n",
      "reduced time to time slot 1 to 144\n",
      "appended day_of_week column to data\n",
      "printing merged data\n",
      "         region_id  time_slot  weather  temperature  PM2.5  \\\n",
      "0                1        126      NaN          NaN    NaN   \n",
      "1                1         79      NaN          NaN    NaN   \n",
      "2                1        127      NaN          NaN    NaN   \n",
      "3                1        117      NaN          NaN    NaN   \n",
      "4                1        124      NaN          NaN    NaN   \n",
      "...            ...        ...      ...          ...    ...   \n",
      "8540609         66         71      NaN          NaN    NaN   \n",
      "8540610         66        131      NaN          NaN    NaN   \n",
      "8540611         66         92      NaN          NaN    NaN   \n",
      "8540612         66         58      NaN          NaN    NaN   \n",
      "8540613         66        109      NaN          NaN    NaN   \n",
      "\n",
      "                                driver_id  price  day_of_week  \n",
      "0        cc26812d679c9e55a6bf63eed315e989    7.0            4  \n",
      "1        f6c760be3cd8521c612657da7788f9dc   11.6            4  \n",
      "2        360478560b1fd4b3eb757074c91ee709    6.0            4  \n",
      "3        0359fc335d238c6206703d1d7e3620c8    7.9            4  \n",
      "4        c03944aff7444c27fd7b04cdd3e80af5    5.0            4  \n",
      "...                                   ...    ...          ...  \n",
      "8540609  a912caec12b517d3488b322419801d61   15.0            3  \n",
      "8540610  052e4bb0838b2ae996d6be084ccdbc88    4.0            3  \n",
      "8540611  e85e82d4832915a0b8eaa160d2a5fbb6   30.0            3  \n",
      "8540612  c63dd44c36a949b191a8e5b828d36106    2.0            3  \n",
      "8540613  15be5323bcd74279bba03d01d81ff5b1   11.0            3  \n",
      "\n",
      "[8540614 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# drop order_id, driver_id, passenger_id, dest_region_hash\n",
    "mergedData = orderData.drop(['order_id', 'passenger_id', 'dest_region_hash'], axis=1)\n",
    "print(\"dropped order_id, passenger_id, dest_region_hash\")\n",
    "#  merge order data with region data on start_region_hash with region_hash\n",
    "mergedData = pd.merge(regionData,mergedData, how='left', right_on='start_region_hash', left_on='region_hash')\n",
    "print(\"merged order data and region data based on region\")\n",
    "\n",
    "mergedData = mergedData.drop(['region_hash','start_region_hash'], axis=1)\n",
    "print(\"dropped region_hash, start_region_hash\")\n",
    "# # reduce time to time slot and update time column\n",
    "mergedData['time'] = mergedData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "print(\"reduced time to time slot 1 to 144\")\n",
    "# rename time to time_slot\n",
    "mergedData.rename(columns={'time':'time_slot'}, inplace=True)\n",
    "# # append column for day of week into mergedData\n",
    "mergedData['day_of_week'] = orderData['time'].apply(extractDayOfWeek)\n",
    "print(\"appended day_of_week column to data\")\n",
    "# now we have mergedData with region_id, price, time, day_of_week\n",
    "print(\"printing merged data\")\n",
    "print(mergedData)\n",
    "\n",
    "# writing to mergedData.csv for quick access\n",
    "mergedData.to_csv('mergedData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mergedData.csv\n",
    "mergedDataCSV = pd.read_csv('mergedData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         region_id  time_slot  weather  temperature  PM2.5  \\\n",
      "0                1        126      NaN          NaN    NaN   \n",
      "1                1         79      NaN          NaN    NaN   \n",
      "2                1        127      NaN          NaN    NaN   \n",
      "3                1        117      NaN          NaN    NaN   \n",
      "4                1        124      NaN          NaN    NaN   \n",
      "...            ...        ...      ...          ...    ...   \n",
      "8540609         66         71      NaN          NaN    NaN   \n",
      "8540610         66        131      NaN          NaN    NaN   \n",
      "8540611         66         92      NaN          NaN    NaN   \n",
      "8540612         66         58      NaN          NaN    NaN   \n",
      "8540613         66        109      NaN          NaN    NaN   \n",
      "\n",
      "                                driver_id  price  day_of_week  \n",
      "0        cc26812d679c9e55a6bf63eed315e989    7.0            4  \n",
      "1        f6c760be3cd8521c612657da7788f9dc   11.6            4  \n",
      "2        360478560b1fd4b3eb757074c91ee709    6.0            4  \n",
      "3        0359fc335d238c6206703d1d7e3620c8    7.9            4  \n",
      "4        c03944aff7444c27fd7b04cdd3e80af5    5.0            4  \n",
      "...                                   ...    ...          ...  \n",
      "8540609  a912caec12b517d3488b322419801d61   15.0            3  \n",
      "8540610  052e4bb0838b2ae996d6be084ccdbc88    4.0            3  \n",
      "8540611  e85e82d4832915a0b8eaa160d2a5fbb6   30.0            3  \n",
      "8540612  c63dd44c36a949b191a8e5b828d36106    2.0            3  \n",
      "8540613  15be5323bcd74279bba03d01d81ff5b1   11.0            3  \n",
      "\n",
      "[8540614 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(mergedDataCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing grouped merged data\n",
      "         region_id  time_slot  weather  temperature  PM2.5  \\\n",
      "0                1        126      NaN          NaN    NaN   \n",
      "1                1         79      NaN          NaN    NaN   \n",
      "2                1        127      NaN          NaN    NaN   \n",
      "3                1        117      NaN          NaN    NaN   \n",
      "4                1        124      NaN          NaN    NaN   \n",
      "...            ...        ...      ...          ...    ...   \n",
      "8540609         66         71      NaN          NaN    NaN   \n",
      "8540610         66        131      NaN          NaN    NaN   \n",
      "8540611         66         92      NaN          NaN    NaN   \n",
      "8540612         66         58      NaN          NaN    NaN   \n",
      "8540613         66        109      NaN          NaN    NaN   \n",
      "\n",
      "                                driver_id  price  day_of_week  requests  \n",
      "0        cc26812d679c9e55a6bf63eed315e989    7.0            4         1  \n",
      "1        f6c760be3cd8521c612657da7788f9dc   11.6            4         1  \n",
      "2        360478560b1fd4b3eb757074c91ee709    6.0            4         1  \n",
      "3        0359fc335d238c6206703d1d7e3620c8    7.9            4         1  \n",
      "4        c03944aff7444c27fd7b04cdd3e80af5    5.0            4         1  \n",
      "...                                   ...    ...          ...       ...  \n",
      "8540609  a912caec12b517d3488b322419801d61   15.0            3         1  \n",
      "8540610  052e4bb0838b2ae996d6be084ccdbc88    4.0            3         1  \n",
      "8540611  e85e82d4832915a0b8eaa160d2a5fbb6   30.0            3         1  \n",
      "8540612  c63dd44c36a949b191a8e5b828d36106    2.0            3         1  \n",
      "8540613  15be5323bcd74279bba03d01d81ff5b1   11.0            3         1  \n",
      "\n",
      "[8540614 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(mergedDataCSV)\n",
    "mergedDataCSV['requests'] = 1\n",
    "groupedMergedDataCSV = mergedDataCSV.groupby(['region_id','time_slot','day_of_week','weather','temperature','PM2.5'])['requests'].agg('sum').reset_index()\n",
    "mergedData = pd.merge(mergedDataCSV,groupedMergedDataCSV, how='left')\n",
    "print(\"printing grouped merged data\")\n",
    "print(mergedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to get req(i,j) we can do that by counting the number of orders for region i and timeslot j\n",
    "def getRequest(i,j): # i is region id and j is timeslot\n",
    "    global orderData\n",
    "    numberOfIterations = len(orderData)\n",
    "    print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "    progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "    requests = 0\n",
    "    for row in range(len(orderData)):\n",
    "        currentRegionID = getRegionID(orderData['start_region_hash'][row])\n",
    "        currentTimeSlot = calculateTimeSlot(orderData['time'][row],False)\n",
    "        if currentRegionID == i and currentTimeSlot == j:\n",
    "            requests += 1\n",
    "        progressBarInit.update(1)\n",
    "    progressBarInit.close()\n",
    "    return requests\n",
    "\n",
    "print(\"Printing request for 1st region and 1st timeslot\")\n",
    "print(getRequest(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dateToIndex(date):\n",
    "#     index = 0\n",
    "    \n",
    "#     return index\n",
    "\n",
    "def getAllRequestAndSupply(): # need to filter by date \n",
    "    global orderData\n",
    "    global regionData\n",
    "    global NUM_TIME_SLOTS\n",
    "    global NUM_DAYS_IN_DATA\n",
    "    numberOfRegions = len(regionData)\n",
    "    numberOfIterations = len(orderData)\n",
    "    print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "    progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "    # 3D requests array requests[i][j][k] is number of requests --> date i ,region j, timeslot k\n",
    "    # requests = [[[0 for k in range(NUM_TIME_SLOTS)] for j in range(numberOfRegions)] for i in range(NUM_DAYS_IN_DATA)]\n",
    "    # supply = [[[0 for k in range(NUM_TIME_SLOTS)] for j in range(numberOfRegions)] for i in range(NUM_DAYS_IN_DATA)]\n",
    "    requests = [[0 for j in range(NUM_TIME_SLOTS)] for i in range(numberOfRegions)]\n",
    "    supply = [[0 for j in range(NUM_TIME_SLOTS)] for i in range(numberOfRegions)]\n",
    "    for row in range(len(orderData)):\n",
    "        currentRegionID = getRegionID(orderData['start_region_hash'][row])\n",
    "        currentTimeSlot = calculateTimeSlot(orderData['time'][row],False)\n",
    "        # date = orderData['time'][row].split(' ')[0]\n",
    "        \n",
    "        if currentRegionID < 0:\n",
    "            print(f\"Region not found for {orderData['start_region_hash'][row]}\")\n",
    "            continue\n",
    "            # return (None,None)\n",
    "        if currentTimeSlot < 0:\n",
    "            print(f\"Time slot not found for {orderData['time'][row]}\")\n",
    "            continue\n",
    "            # return (None,None)\n",
    "        if currentRegionID > numberOfRegions:\n",
    "            print(f\"Region id {currentRegionID} is greater than number of regions {numberOfRegions}\")\n",
    "            continue\n",
    "            # return (None,None)\n",
    "        if currentTimeSlot > NUM_TIME_SLOTS:\n",
    "            print(f\"Time slot {currentTimeSlot} is greater than number of time slots {NUM_TIME_SLOTS}\")\n",
    "            print(f\"Time: {orderData['time'][row]}\")\n",
    "            print(f\"Row: {row}\")\n",
    "            continue\n",
    "            # return (None,None)\n",
    "        if currentTimeSlot == 0:\n",
    "            print(f\"Time slot is 0 for {orderData['time'][row]}\")\n",
    "            print(f\"Row: {row}\")\n",
    "            continue\n",
    "            # return (None,None)\n",
    "        # requests[currentDate][currentRegionID-1][currentTimeSlot-1] += 1\n",
    "        requests[currentRegionID-1][currentTimeSlot-1] += 1\n",
    "        if type(orderData['driver_id'][row]) == str:\n",
    "            supply[currentRegionID-1][currentTimeSlot-1] += 1\n",
    "            # supply[currentDate][currentRegionID-1][currentTimeSlot-1] += 1\n",
    "        progressBarInit.update(1)\n",
    "    progressBarInit.close()\n",
    "    return (requests,supply)\n",
    "\n",
    "print(\"Printing request and supply regions d(i) and timeslots t(j)\")\n",
    "(request,supply) = getAllRequestAndSupply()\n",
    "print(request)\n",
    "print(supply) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npRequest = np.array(request)\n",
    "npSupply = np.array(supply)\n",
    "np.savetxt('request.csv', npRequest, delimiter=',')\n",
    "np.savetxt('supply.csv', npSupply, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to get req(i,j) we can do that by counting the number of orders for region i and timeslot j\n",
    "# # concurrentI =0\n",
    "# # concurrentJ =0\n",
    "# def getRequestMulti(data, i, j,lowerIndex,upperIndex):\n",
    "#     # (orderData, i, j,lowerIndex,upperIndex) = arguments\n",
    "#     numberOfIterations = upperIndex - lowerIndex\n",
    "#     currentPID = mp.current_process()._identity[0]-1\n",
    "#     # logging.info(f\"process {currentPID}\")\n",
    "#     print(f\"Number of lines of data: {numberOfIterations} for process {currentPID}\")\n",
    "#     # progressBarInit = tqdm(total=numberOfIterations, desc=f\"Calculating requests {currentPID}\", unit=\" lines\")\n",
    "#     lowerIndex = lowerIndex[currentPID]\n",
    "#     upperIndex = upperIndex[currentPID]\n",
    "#     requests = 0\n",
    "#     for row in range(lowerIndex,upperIndex):\n",
    "#         currentRegionID = getRegionID(data['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(data['time'][row],False)\n",
    "#         if currentRegionID == i and currentTimeSlot == j:\n",
    "#             requests += 1\n",
    "#         # progressBarInit.update(1)\n",
    "#     # progressBarInit.close()\n",
    "#     return requests\n",
    "\n",
    "# def getRequestHelper(i,j): # i is region id and j is timeslot\n",
    "#     global orderData\n",
    "#     # global concurrentI\n",
    "#     # global concurrentJ\n",
    "#     # concurrentJ = j\n",
    "#     # concurrentI = i\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     # logging.basicConfig(level=logging.INFO,filename='worker.log', filemode='w')\n",
    "#     # console_handler = logging.StreamHandler()\n",
    "#     # logging.getLogger().addHandler(console_handler)\n",
    "#     # print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     # progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "    \n",
    "#     numberOfProcessesToRun = mp.cpu_count()\n",
    "#     print(f\"CPUs: {numberOfProcessesToRun}\")\n",
    "#     multiProcessingPool = mp.Pool(numberOfProcessesToRun)\n",
    "#     upperIndex = []\n",
    "#     lowerIndex = []\n",
    "#     for i in range(numberOfProcessesToRun):\n",
    "#         lowerval = i*numberOfIterations//numberOfProcessesToRun\n",
    "#         upperVal = (i+1)*numberOfIterations//numberOfProcessesToRun\n",
    "#         lowerIndex.append(lowerval)\n",
    "#         upperIndex.append(upperVal)\n",
    "#     print(\"Here\")\n",
    "#     # argumentsToPass = (orderData, i, j,lowerIndex, upperIndex)\n",
    "#     requests = multiProcessingPool.starmap(getRequestMulti, [(orderData, i, j,lowerIndex, upperIndex)])\n",
    "#     requests = sum(requests)\n",
    "#     multiProcessingPool.close()\n",
    "#     multiProcessingPool.join()\n",
    "#     return requests\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Printing request for 1st region and 1st timeslot\")\n",
    "# print(getRequestHelper(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
