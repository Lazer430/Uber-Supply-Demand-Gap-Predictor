{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install tqdm\n",
    "# !pip install sklearn\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is dev branch\n",
    "import datetime\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "\n",
    "NUM_TIME_SLOTS = 144\n",
    "NUM_DAYS_IN_DATA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "# 24 hours is divided into 144 slots where each slot is 10 mins long\n",
    "def calculateTimeSlot(time,printValue=True):\n",
    "    global NUM_TIME_SLOTS\n",
    "    dateTime = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    timePart = dateTime.time()\n",
    "    timeInMinutes = (timePart.hour * 60) + timePart.minute + (timePart.second/60) + 1\n",
    "    timeSlot = timeInMinutes/10\n",
    "    roundedTimeSlot = math.ceil(timeSlot)\n",
    "    if roundedTimeSlot > NUM_TIME_SLOTS:\n",
    "        roundedTimeSlot -= 1\n",
    "    if printValue==True:\n",
    "        print(f\"time: {time} timeInMinutes: {timeInMinutes} timeSlot: {roundedTimeSlot}\")\n",
    "    return int(roundedTimeSlot)\n",
    "\n",
    "def extractDayOfWeek(time):\n",
    "    d = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    return d.weekday()\n",
    "\n",
    "def extractDate(time):\n",
    "    d = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    return d.date()\n",
    "\n",
    "print(type(extractDate('2019-01-01 00:00:00')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNumberOfPOI(poiArray):\n",
    "    poiCount = 0\n",
    "    for poiEntry in poiArray:\n",
    "        poiEntry = poiEntry + ':'\n",
    "        divisions = poiEntry.split(\":\")\n",
    "        poiCount += int(divisions[1])\n",
    "    return poiCount\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMultipleData(path,fileNamePrefix,headerNames,dataTypes):\n",
    "    global NUM_DAYS_IN_DATA\n",
    "    filesToExplore = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.startswith(fileNamePrefix):\n",
    "            filesToExplore.append(file)\n",
    "            # print(f\"{file} read\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    print(f\"{len(filesToExplore)} files read\")\n",
    "    if fileNamePrefix == 'order':\n",
    "        NUM_DAYS_IN_DATA = len(filesToExplore)\n",
    "    \n",
    "    readData = []\n",
    "    for files in filesToExplore:\n",
    "        fileRead = pd.read_csv(path + files, sep='\\t', names=headerNames,dtype=dataTypes)\n",
    "        readData.append(fileRead)\n",
    "\n",
    "    readData = pd.concat(readData, ignore_index=True)\n",
    "    return readData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now region Data\n",
    "regionData = pd.read_csv('./training_data/cluster_map/cluster_map', sep='\\t', names=['region_hash', 'region_id'],dtype={'region_hash': 'str', 'region_id': 'int'})\n",
    "# print(regionData.head())\n",
    "regionData.to_csv('regionData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 files read\n",
      "printing order data\n"
     ]
    }
   ],
   "source": [
    "# read order data\n",
    "dataTypes = {'order_id':'str', 'driver_id':'str', 'passenger_id':'str', 'start_region_hash':'str', 'dest_region_hash':'str', 'price':'double', 'time':'str'}\n",
    "orderDataPath = './training_data/order_data/'\n",
    "orderData = readMultipleData(orderDataPath,'order', ['order_id', 'driver_id', 'passenger_id', 'start_region_hash', 'dest_region_hash', 'price', 'time'], dataTypes)\n",
    "print(\"printing order data\")\n",
    "# print(orderData.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 files read\n",
      "printing weather data\n"
     ]
    }
   ],
   "source": [
    "# read weather data\n",
    "dataTypes={'time':'str', 'weather':'int', 'temperature':'double', 'PM2.5':'double'}\n",
    "weatherDataPath = './training_data/weather_data/'\n",
    "weatherData = readMultipleData(weatherDataPath,'weather', ['time', 'weather', 'temperature', 'PM2.5'], dataTypes)\n",
    "print(\"printing weather data\")\n",
    "# print(weatherData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date\n",
      "0        1          1  2016-01-01\n",
      "1        1          1  2016-01-01\n",
      "2        1          2  2016-01-01\n",
      "3        1          2  2016-01-01\n",
      "4        1          3  2016-01-01\n"
     ]
    }
   ],
   "source": [
    "weatherData['time_slot'] = weatherData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "weatherData['date'] = weatherData['time'].apply(extractDate)\n",
    "# weatherData['day_of_week'] = weatherData['time'].apply(extractDayOfWeek)\n",
    "weatherData = weatherData.drop(['temperature','PM2.5','time'], axis=1)\n",
    "print(weatherData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        region_hash  region_id   \n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1  \\\n",
      "1  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "2  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "3  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "4  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "\n",
      "                           order_id                         driver_id   \n",
      "0  1654babc363bc6d0f5d01fc0bafedc1a  cc26812d679c9e55a6bf63eed315e989  \\\n",
      "1  5ac4ac8d0e6092ea1dc323d367613ffd  f6c760be3cd8521c612657da7788f9dc   \n",
      "2  ce86a6ae5eee7a2ea954323b6c01510b  360478560b1fd4b3eb757074c91ee709   \n",
      "3  b5e816c08e44565c7ed67a6f6e366708  0359fc335d238c6206703d1d7e3620c8   \n",
      "4  25ed10b13aaa36071deecab3aa374be3  c03944aff7444c27fd7b04cdd3e80af5   \n",
      "\n",
      "                  time  time_slot  day_of_week        date  \n",
      "0  2016-01-01 20:49:15        126            4  2016-01-01  \n",
      "1  2016-01-01 13:04:32         79            4  2016-01-01  \n",
      "2  2016-01-01 21:00:21        127            4  2016-01-01  \n",
      "3  2016-01-01 19:25:32        117            4  2016-01-01  \n",
      "4  2016-01-01 20:35:36        124            4  2016-01-01  \n"
     ]
    }
   ],
   "source": [
    "orderData = pd.merge(regionData,orderData, how='left', right_on='start_region_hash', left_on='region_hash')\n",
    "orderData['time_slot'] = orderData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "orderData['day_of_week'] = orderData['time'].apply(extractDayOfWeek)\n",
    "orderData['date'] = orderData['time'].apply(extractDate)\n",
    "orderData = orderData.drop(['passenger_id', 'dest_region_hash','start_region_hash','price'], axis=1)\n",
    "print(orderData.head())\n",
    "# regionData=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash   \n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a  \\\n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id   \n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9  \\\n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4  \n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4  \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4  \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4  \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4  \n"
     ]
    }
   ],
   "source": [
    "mergedOrderData = pd.merge(weatherData,orderData, how=\"inner\", on=['date','time_slot'])\n",
    "print(mergedOrderData.head())\n",
    "# orderData.to_csv('orderData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData=None\n",
    "orderData = mergedOrderData\n",
    "# orderData.to_csv('mergedOrderData.csv',index=False)\n",
    "# type(orderData['driver_id'][4])==float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orderData = pd.read_csv('mergedOrderData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region_id  poi_count\n",
      "0          1     653376\n",
      "1          2     343537\n",
      "2          3      31125\n",
      "3          4     187829\n",
      "4          5      27888\n"
     ]
    }
   ],
   "source": [
    "# read POI Data\n",
    "poiDataStr = {\n",
    "    'region_hash':[],\n",
    "    'poi_class':[]\n",
    "}\n",
    "with open('./training_data/poi_data/poi_data','r') as fileToRead:\n",
    "    for line in fileToRead:\n",
    "        line = line.strip()\n",
    "        columns = line.split('\\t')\n",
    "        poiDataStr['region_hash'].append(columns[0])\n",
    "        remData = columns[1:]\n",
    "        poiDataStr['poi_class'].append(remData)\n",
    "        \n",
    "poiData = pd.DataFrame(poiDataStr,columns=['region_hash','poi_class'])\n",
    "poiData['poi_count'] = poiData['poi_class'].apply(extractNumberOfPOI)\n",
    "poiData = pd.merge(regionData,poiData, how='inner', on='region_hash')\n",
    "poiData = poiData.drop(['region_hash'], axis=1)\n",
    "poiData = poiData.drop(['poi_class'], axis=1)\n",
    "print(poiData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash   \n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a  \\\n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id   \n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9  \\\n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week   \n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4  \\\n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "\n",
      "   poi_count  \n",
      "0     653376  \n",
      "1     653376  \n",
      "2     653376  \n",
      "3     653376  \n",
      "4     653376  \n"
     ]
    }
   ],
   "source": [
    "orderData = pd.merge(orderData,poiData, how=\"inner\", on='region_id')\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash   \n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a  \\\n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id   \n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9  \\\n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week   \n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4  \\\n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "\n",
      "   poi_count  requests_x  requests_y  \n",
      "0     653376           1         330  \n",
      "1     653376           1         330  \n",
      "2     653376           1         330  \n",
      "3     653376           1         330  \n",
      "4     653376           1         330  \n"
     ]
    }
   ],
   "source": [
    "# print(mergedDataCSV)\n",
    "orderData['requests'] = 1\n",
    "# print(orderData.head())\n",
    "groupedMergedData = orderData.groupby(['region_id','time_slot','day_of_week','weather','poi_count'])['requests'].agg('sum').reset_index()\n",
    "# groupedMergedData = groupedMergedData.drop(['date','region_hash','order_id','driver_id','time'], axis=1)\n",
    "orderData = pd.merge(orderData,groupedMergedData, how='left' , on=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash   \n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a  \\\n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id   \n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9  \\\n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week   \n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4  \\\n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "\n",
      "   poi_count  requests  \n",
      "0     653376       330  \n",
      "1     653376       330  \n",
      "2     653376       330  \n",
      "3     653376       330  \n",
      "4     653376       330  \n"
     ]
    }
   ],
   "source": [
    "orderData = orderData.drop([\"requests_x\"], axis=1)\n",
    "orderData = orderData.rename(columns={\"requests_y\": \"requests\"})\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          weather  time_slot        date                       region_hash   \n",
      "0               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a  \\\n",
      "1               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "...           ...        ...         ...                               ...   \n",
      "12222999        2        141  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223000        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223001        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223002        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223003        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "\n",
      "          region_id                          order_id   \n",
      "0                 1  df1dc94f51fec68d3116e4b6bd8480a9  \\\n",
      "1                 1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2                 1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3                 1  74d98ad919a078a4c084098e2fdef219   \n",
      "4                 1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "...             ...                               ...   \n",
      "12222999         62  31ca3cf08e2886eed36e9377933c2990   \n",
      "12223000         62  1068450007355a22907fded661ce2939   \n",
      "12223001         62  9555828a2e7ac1e6e2197e20bde65f8b   \n",
      "12223002         62  1068450007355a22907fded661ce2939   \n",
      "12223003         62  9555828a2e7ac1e6e2197e20bde65f8b   \n",
      "\n",
      "                                 driver_id                 time  day_of_week   \n",
      "0         9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4  \\\n",
      "1         3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2         448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3         ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4         424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "...                                    ...                  ...          ...   \n",
      "12222999                               NaN  2016-01-21 23:20:05            3   \n",
      "12223000                               NaN  2016-01-21 23:32:52            3   \n",
      "12223001                               NaN  2016-01-21 23:36:52            3   \n",
      "12223002                               NaN  2016-01-21 23:32:52            3   \n",
      "12223003                               NaN  2016-01-21 23:36:52            3   \n",
      "\n",
      "          poi_count  requests  answers_x  answers_y  \n",
      "0            653376       330          1        314  \n",
      "1            653376       330          1        314  \n",
      "2            653376       330          1        314  \n",
      "3            653376       330          1        314  \n",
      "4            653376       330          1        314  \n",
      "...             ...       ...        ...        ...  \n",
      "12222999       2988         2          0          0  \n",
      "12223000       2988         4          0          0  \n",
      "12223001       2988         4          0          0  \n",
      "12223002       2988         4          0          0  \n",
      "12223003       2988         4          0          0  \n",
      "\n",
      "[12223004 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "orderData['temp'] = 1\n",
    "orderData['answers'] = orderData['temp'].where(orderData['driver_id'].notnull(), 0)\n",
    "orderData = orderData.drop(['temp'], axis=1)\n",
    "groupedMergedData = orderData.groupby(['region_id','time_slot','day_of_week','weather','poi_count'])['answers'].agg('sum').reset_index()\n",
    "orderData = pd.merge(orderData,groupedMergedData, how='left' , on=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "print(orderData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = orderData.drop([\"answers_x\"], axis=1)\n",
    "orderData = orderData.rename(columns={\"answers_y\": \"answers\"})\n",
    "orderData.to_csv('mergedOrderData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          weather  time_slot        date                       region_hash   \n",
      "0               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a  \\\n",
      "1               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "...           ...        ...         ...                               ...   \n",
      "12222999        2        141  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223000        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223001        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223002        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223003        2        142  2016-01-21  a735449c5c09df639c35a7d61fad3ee5   \n",
      "\n",
      "          region_id                          order_id   \n",
      "0                 1  df1dc94f51fec68d3116e4b6bd8480a9  \\\n",
      "1                 1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2                 1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3                 1  74d98ad919a078a4c084098e2fdef219   \n",
      "4                 1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "...             ...                               ...   \n",
      "12222999         62  31ca3cf08e2886eed36e9377933c2990   \n",
      "12223000         62  1068450007355a22907fded661ce2939   \n",
      "12223001         62  9555828a2e7ac1e6e2197e20bde65f8b   \n",
      "12223002         62  1068450007355a22907fded661ce2939   \n",
      "12223003         62  9555828a2e7ac1e6e2197e20bde65f8b   \n",
      "\n",
      "                                 driver_id                 time  day_of_week   \n",
      "0         9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4  \\\n",
      "1         3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2         448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3         ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4         424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "...                                    ...                  ...          ...   \n",
      "12222999                               NaN  2016-01-21 23:20:05            3   \n",
      "12223000                               NaN  2016-01-21 23:32:52            3   \n",
      "12223001                               NaN  2016-01-21 23:36:52            3   \n",
      "12223002                               NaN  2016-01-21 23:32:52            3   \n",
      "12223003                               NaN  2016-01-21 23:36:52            3   \n",
      "\n",
      "          poi_count  requests  answers  supply_demand  \n",
      "0            653376       330      314             16  \n",
      "1            653376       330      314             16  \n",
      "2            653376       330      314             16  \n",
      "3            653376       330      314             16  \n",
      "4            653376       330      314             16  \n",
      "...             ...       ...      ...            ...  \n",
      "12222999       2988         2        0              2  \n",
      "12223000       2988         4        0              4  \n",
      "12223001       2988         4        0              4  \n",
      "12223002       2988         4        0              4  \n",
      "12223003       2988         4        0              4  \n",
      "\n",
      "[12223004 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "orderData['supply_demand'] = orderData['requests'] - orderData['answers']\n",
    "print(orderData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make rolling window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to calculate gap(i,j) = req(i,j) - supply(i,j)\n",
    "# # req(i,j) is for region i and timeslot j \n",
    "# # ith region will be from from start_region_hash and jth timeslot will be calculated from time\n",
    "# def getRegionID(regionHash):\n",
    "#     regionID = -1\n",
    "#     for i in range(len(regionData)):\n",
    "#         if regionHash == regionData['region_hash'][i]:\n",
    "#             regionID = regionData['region_id'][i]\n",
    "#     return regionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergedData = None # here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop order_id, driver_id, passenger_id, dest_region_hash\n",
    "# mergedData = orderData.drop(['order_id', 'passenger_id', 'dest_region_hash'], axis=1)\n",
    "# print(\"dropped order_id, passenger_id, dest_region_hash\")\n",
    "#  merge order data with region data on start_region_hash with region_hash\n",
    "# mergedData = pd.merge(regionData,mergedData, how='left', right_on='start_region_hash', left_on='region_hash')\n",
    "# print(\"merged order data and region data based on region\")\n",
    "\n",
    "# mergedData = mergedData.drop(['region_hash','start_region_hash'], axis=1)\n",
    "# print(\"dropped region_hash, start_region_hash\")\n",
    "# # reduce time to time slot and update time column\n",
    "# mergedData['time'] = mergedData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "# print(\"reduced time to time slot 1 to 144\")\n",
    "# rename time to time_slot\n",
    "# mergedData.rename(columns={'time':'time_slot'}, inplace=True)\n",
    "# # append column for day of week into mergedData\n",
    "# mergedData['day_of_week'] = orderData['time'].apply(extractDayOfWeek)\n",
    "# print(\"appended day_of_week column to data\")\n",
    "# now we have mergedData with region_id, price, time, day_of_week\n",
    "# print(\"printing merged data\")\n",
    "# print(mergedData)\n",
    "\n",
    "# writing to mergedData.csv for quick access\n",
    "# orderData.to_csv('mergedData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mergedData.csv\n",
    "# mergedDataCSV = pd.read_csv('mergedData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mergedDataCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to get req(i,j) we can do that by counting the number of orders for region i and timeslot j\n",
    "# def getRequest(i,j): # i is region id and j is timeslot\n",
    "#     global orderData\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "#     requests = 0\n",
    "#     for row in range(len(orderData)):\n",
    "#         currentRegionID = getRegionID(orderData['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(orderData['time'][row],False)\n",
    "#         if currentRegionID == i and currentTimeSlot == j:\n",
    "#             requests += 1\n",
    "#         progressBarInit.update(1)\n",
    "#     progressBarInit.close()\n",
    "#     return requests\n",
    "\n",
    "# print(\"Printing request for 1st region and 1st timeslot\")\n",
    "# print(getRequest(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def dateToIndex(date):\n",
    "# #     index = 0\n",
    "    \n",
    "# #     return index\n",
    "\n",
    "# def getAllRequestAndSupply(): # need to filter by date \n",
    "#     global orderData\n",
    "#     global regionData\n",
    "#     global NUM_TIME_SLOTS\n",
    "#     global NUM_DAYS_IN_DATA\n",
    "#     numberOfRegions = len(regionData)\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "#     # 3D requests array requests[i][j][k] is number of requests --> date i ,region j, timeslot k\n",
    "#     # requests = [[[0 for k in range(NUM_TIME_SLOTS)] for j in range(numberOfRegions)] for i in range(NUM_DAYS_IN_DATA)]\n",
    "#     # supply = [[[0 for k in range(NUM_TIME_SLOTS)] for j in range(numberOfRegions)] for i in range(NUM_DAYS_IN_DATA)]\n",
    "#     requests = [[0 for j in range(NUM_TIME_SLOTS)] for i in range(numberOfRegions)]\n",
    "#     supply = [[0 for j in range(NUM_TIME_SLOTS)] for i in range(numberOfRegions)]\n",
    "#     for row in range(len(orderData)):\n",
    "#         currentRegionID = getRegionID(orderData['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(orderData['time'][row],False)\n",
    "#         # date = orderData['time'][row].split(' ')[0]\n",
    "        \n",
    "#         if currentRegionID < 0:\n",
    "#             print(f\"Region not found for {orderData['start_region_hash'][row]}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot < 0:\n",
    "#             print(f\"Time slot not found for {orderData['time'][row]}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentRegionID > numberOfRegions:\n",
    "#             print(f\"Region id {currentRegionID} is greater than number of regions {numberOfRegions}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot > NUM_TIME_SLOTS:\n",
    "#             print(f\"Time slot {currentTimeSlot} is greater than number of time slots {NUM_TIME_SLOTS}\")\n",
    "#             print(f\"Time: {orderData['time'][row]}\")\n",
    "#             print(f\"Row: {row}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot == 0:\n",
    "#             print(f\"Time slot is 0 for {orderData['time'][row]}\")\n",
    "#             print(f\"Row: {row}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         # requests[currentDate][currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         requests[currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         if type(orderData['driver_id'][row]) == str:\n",
    "#             supply[currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#             # supply[currentDate][currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         progressBarInit.update(1)\n",
    "#     progressBarInit.close()\n",
    "#     return (requests,supply)\n",
    "\n",
    "# print(\"Printing request and supply regions d(i) and timeslots t(j)\")\n",
    "# (request,supply) = getAllRequestAndSupply()\n",
    "# print(request)\n",
    "# print(supply) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npRequest = np.array(request)\n",
    "# npSupply = np.array(supply)\n",
    "# np.savetxt('request.csv', npRequest, delimiter=',')\n",
    "# np.savetxt('supply.csv', npSupply, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to get req(i,j) we can do that by counting the number of orders for region i and timeslot j\n",
    "# # concurrentI =0\n",
    "# # concurrentJ =0\n",
    "# def getRequestMulti(data, i, j,lowerIndex,upperIndex):\n",
    "#     # (orderData, i, j,lowerIndex,upperIndex) = arguments\n",
    "#     numberOfIterations = upperIndex - lowerIndex\n",
    "#     currentPID = mp.current_process()._identity[0]-1\n",
    "#     # logging.info(f\"process {currentPID}\")\n",
    "#     print(f\"Number of lines of data: {numberOfIterations} for process {currentPID}\")\n",
    "#     # progressBarInit = tqdm(total=numberOfIterations, desc=f\"Calculating requests {currentPID}\", unit=\" lines\")\n",
    "#     lowerIndex = lowerIndex[currentPID]\n",
    "#     upperIndex = upperIndex[currentPID]\n",
    "#     requests = 0\n",
    "#     for row in range(lowerIndex,upperIndex):\n",
    "#         currentRegionID = getRegionID(data['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(data['time'][row],False)\n",
    "#         if currentRegionID == i and currentTimeSlot == j:\n",
    "#             requests += 1\n",
    "#         # progressBarInit.update(1)\n",
    "#     # progressBarInit.close()\n",
    "#     return requests\n",
    "\n",
    "# def getRequestHelper(i,j): # i is region id and j is timeslot\n",
    "#     global orderData\n",
    "#     # global concurrentI\n",
    "#     # global concurrentJ\n",
    "#     # concurrentJ = j\n",
    "#     # concurrentI = i\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     # logging.basicConfig(level=logging.INFO,filename='worker.log', filemode='w')\n",
    "#     # console_handler = logging.StreamHandler()\n",
    "#     # logging.getLogger().addHandler(console_handler)\n",
    "#     # print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     # progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "    \n",
    "#     numberOfProcessesToRun = mp.cpu_count()\n",
    "#     print(f\"CPUs: {numberOfProcessesToRun}\")\n",
    "#     multiProcessingPool = mp.Pool(numberOfProcessesToRun)\n",
    "#     upperIndex = []\n",
    "#     lowerIndex = []\n",
    "#     for i in range(numberOfProcessesToRun):\n",
    "#         lowerval = i*numberOfIterations//numberOfProcessesToRun\n",
    "#         upperVal = (i+1)*numberOfIterations//numberOfProcessesToRun\n",
    "#         lowerIndex.append(lowerval)\n",
    "#         upperIndex.append(upperVal)\n",
    "#     print(\"Here\")\n",
    "#     # argumentsToPass = (orderData, i, j,lowerIndex, upperIndex)\n",
    "#     requests = multiProcessingPool.starmap(getRequestMulti, [(orderData, i, j,lowerIndex, upperIndex)])\n",
    "#     requests = sum(requests)\n",
    "#     multiProcessingPool.close()\n",
    "#     multiProcessingPool.join()\n",
    "#     return requests\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Printing request for 1st region and 1st timeslot\")\n",
    "# print(getRequestHelper(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
