{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install tqdm\n",
    "# !pip install sklearn\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is dev branch\n",
    "import datetime\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "\n",
    "NUM_TIME_SLOTS = 144\n",
    "NUM_DAYS_IN_DATA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "# 24 hours is divided into 144 slots where each slot is 10 mins long\n",
    "def calculateTimeSlot(time,printValue=True):\n",
    "    global NUM_TIME_SLOTS\n",
    "    dateTime = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    timePart = dateTime.time()\n",
    "    timeInMinutes = (timePart.hour * 60) + timePart.minute + (timePart.second/60) + 1\n",
    "    timeSlot = timeInMinutes/10\n",
    "    roundedTimeSlot = math.ceil(timeSlot)\n",
    "    if roundedTimeSlot > NUM_TIME_SLOTS:\n",
    "        roundedTimeSlot -= 1\n",
    "    if printValue==True:\n",
    "        print(f\"time: {time} timeInMinutes: {timeInMinutes} timeSlot: {roundedTimeSlot}\")\n",
    "    return int(roundedTimeSlot)\n",
    "\n",
    "def extractDayOfWeek(time):\n",
    "    d = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    return d.weekday()\n",
    "\n",
    "def extractDate(time):\n",
    "    d = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    return d.date()\n",
    "\n",
    "print(type(extractDate('2019-01-01 00:00:00')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNumberOfPOI(poiArray):\n",
    "    poiCount = 0\n",
    "    for poiEntry in poiArray:\n",
    "        poiEntry = poiEntry + ':'\n",
    "        divisions = poiEntry.split(\":\")\n",
    "        poiCount += int(divisions[1])\n",
    "    return poiCount\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMultipleData(path,fileNamePrefix,headerNames,dataTypes,delimiter2=\"\\t\"):\n",
    "    global NUM_DAYS_IN_DATA\n",
    "    filesToExplore = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.startswith(fileNamePrefix):\n",
    "            filesToExplore.append(file)\n",
    "            # print(f\"{file} read\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    print(f\"{len(filesToExplore)} files read\")\n",
    "    if fileNamePrefix == 'order':\n",
    "        NUM_DAYS_IN_DATA = len(filesToExplore)\n",
    "    \n",
    "    readData = []\n",
    "    for files in filesToExplore:\n",
    "        fileRead = pd.read_csv(path + files, sep=delimiter2, names=headerNames,dtype=dataTypes)\n",
    "        readData.append(fileRead)\n",
    "\n",
    "    readData = pd.concat(readData, ignore_index=True)\n",
    "    return readData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now region Data\n",
    "regionData = pd.read_csv('./training_data/cluster_map/cluster_map', sep='\\t', names=['region_hash', 'region_id'],dtype={'region_hash': 'str', 'region_id': 'int'})\n",
    "# print(regionData.head())\n",
    "regionData.to_csv('regionData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 files read\n",
      "printing order data\n"
     ]
    }
   ],
   "source": [
    "# read order data\n",
    "dataTypes = {'order_id':'str', 'driver_id':'str', 'passenger_id':'str', 'start_region_hash':'str', 'dest_region_hash':'str', 'price':'double', 'time':'str'}\n",
    "orderDataPath = './training_data/order_data/'\n",
    "orderData = readMultipleData(orderDataPath,'order', ['order_id', 'driver_id', 'passenger_id', 'start_region_hash', 'dest_region_hash', 'price', 'time'], dataTypes)\n",
    "print(\"printing order data\")\n",
    "# print(orderData.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 files read\n",
      "printing weather data\n"
     ]
    }
   ],
   "source": [
    "# read weather data\n",
    "dataTypes={'time':'str', 'weather':'int', 'temperature':'double', 'PM2.5':'double'}\n",
    "weatherDataPath = './training_data/weather_data/'\n",
    "weatherData = readMultipleData(weatherDataPath,'weather', ['time', 'weather', 'temperature', 'PM2.5'], dataTypes)\n",
    "print(\"printing weather data\")\n",
    "# print(weatherData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date\n",
      "0        1          1  2016-01-01\n",
      "1        1          1  2016-01-01\n",
      "2        1          2  2016-01-01\n",
      "3        1          2  2016-01-01\n",
      "4        1          3  2016-01-01\n"
     ]
    }
   ],
   "source": [
    "weatherData['time_slot'] = weatherData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "weatherData['date'] = weatherData['time'].apply(extractDate)\n",
    "# weatherData['day_of_week'] = weatherData['time'].apply(extractDayOfWeek)\n",
    "weatherData = weatherData.drop(['temperature','PM2.5','time'], axis=1)\n",
    "print(weatherData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        region_hash  region_id  \\\n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "1  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "2  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "3  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "4  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "\n",
      "                           order_id                         driver_id  \\\n",
      "0  a21153d78caad6117ae7a7c1e456fe49  5a9fa443a4824c8d8ec0c210dfe57774   \n",
      "1  359f767cb703721f07e59f839a55230d  cd766c70d6db45140cd39c319db65057   \n",
      "2  d0b97274f30a8b9c02d483581e975ad4  0359fc335d238c6206703d1d7e3620c8   \n",
      "3  b9004db345b0b097c4f6daa66c7d2e6e  c18455b7ad9444ad9b44d534182aeb9f   \n",
      "4  21a9c02f774ff068b2165f715378f9f7  611ae91b57a0b0d458eb96455f50a6cb   \n",
      "\n",
      "                  time  time_slot  day_of_week        date  \n",
      "0  2016-01-04 16:10:14         98            0  2016-01-04  \n",
      "1  2016-01-04 18:41:03        113            0  2016-01-04  \n",
      "2  2016-01-04 10:22:37         63            0  2016-01-04  \n",
      "3  2016-01-04 07:06:46         43            0  2016-01-04  \n",
      "4  2016-01-04 18:37:12        112            0  2016-01-04  \n"
     ]
    }
   ],
   "source": [
    "orderData = pd.merge(regionData,orderData, how='left', right_on='start_region_hash', left_on='region_hash')\n",
    "orderData['time_slot'] = orderData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "orderData['day_of_week'] = orderData['time'].apply(extractDayOfWeek)\n",
    "orderData['date'] = orderData['time'].apply(extractDate)\n",
    "orderData = orderData.drop(['passenger_id', 'dest_region_hash','start_region_hash','price'], axis=1)\n",
    "print(orderData.head())\n",
    "# regionData=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4  \n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4  \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4  \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4  \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4  \n"
     ]
    }
   ],
   "source": [
    "mergedOrderData = pd.merge(weatherData,orderData, how=\"inner\", on=['date','time_slot'])\n",
    "print(mergedOrderData.head())\n",
    "# orderData.to_csv('orderData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData=None\n",
    "orderData = mergedOrderData\n",
    "# orderData.to_csv('mergedOrderData.csv',index=False)\n",
    "# type(orderData['driver_id'][4])==float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orderData = pd.read_csv('mergedOrderData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region_id  poi_count\n",
      "0          1     653376\n",
      "1          2     343537\n",
      "2          3      31125\n",
      "3          4     187829\n",
      "4          5      27888\n"
     ]
    }
   ],
   "source": [
    "# read POI Data\n",
    "poiDataStr = {\n",
    "    'region_hash':[],\n",
    "    'poi_class':[]\n",
    "}\n",
    "with open('./training_data/poi_data/poi_data','r') as fileToRead:\n",
    "    for line in fileToRead:\n",
    "        line = line.strip()\n",
    "        columns = line.split('\\t')\n",
    "        poiDataStr['region_hash'].append(columns[0])\n",
    "        remData = columns[1:]\n",
    "        poiDataStr['poi_class'].append(remData)\n",
    "        \n",
    "poiData = pd.DataFrame(poiDataStr,columns=['region_hash','poi_class'])\n",
    "poiData['poi_count'] = poiData['poi_class'].apply(extractNumberOfPOI)\n",
    "poiData = pd.merge(regionData,poiData, how='inner', on='region_hash')\n",
    "poiData = poiData.drop(['region_hash'], axis=1)\n",
    "poiData = poiData.drop(['poi_class'], axis=1)\n",
    "print(poiData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4   \n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "\n",
      "   poi_count  \n",
      "0     653376  \n",
      "1     653376  \n",
      "2     653376  \n",
      "3     653376  \n",
      "4     653376  \n"
     ]
    }
   ],
   "source": [
    "orderData = pd.merge(orderData,poiData, how=\"inner\", on='region_id')\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4   \n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "\n",
      "   poi_count  requests_x  requests_y  \n",
      "0     653376           1         330  \n",
      "1     653376           1         330  \n",
      "2     653376           1         330  \n",
      "3     653376           1         330  \n",
      "4     653376           1         330  \n"
     ]
    }
   ],
   "source": [
    "# print(mergedDataCSV)\n",
    "orderData['requests'] = 1\n",
    "# print(orderData.head())\n",
    "groupedMergedData = orderData.groupby(['region_id','time_slot','day_of_week','weather','poi_count'])['requests'].agg('sum').reset_index()\n",
    "# groupedMergedData = groupedMergedData.drop(['date','region_hash','order_id','driver_id','time'], axis=1)\n",
    "orderData = pd.merge(orderData,groupedMergedData, how='left' , on=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4   \n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "\n",
      "   poi_count  requests  \n",
      "0     653376       330  \n",
      "1     653376       330  \n",
      "2     653376       330  \n",
      "3     653376       330  \n",
      "4     653376       330  \n"
     ]
    }
   ],
   "source": [
    "orderData = orderData.drop([\"requests_x\"], axis=1)\n",
    "orderData = orderData.rename(columns={\"requests_y\": \"requests\"})\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          weather  time_slot        date                       region_hash  \\\n",
      "0               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "...           ...        ...         ...                               ...   \n",
      "12222999        2        135  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223000        2        135  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223001        2        137  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223002        2        140  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223003        2        140  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "\n",
      "          region_id                          order_id  \\\n",
      "0                 1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1                 1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2                 1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3                 1  74d98ad919a078a4c084098e2fdef219   \n",
      "4                 1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "...             ...                               ...   \n",
      "12222999         62  c43f09e0c3ee010bfd4c382a1bf5e009   \n",
      "12223000         62  a9fc1e22645810caa2f229c5250f4e60   \n",
      "12223001         62  02ae325b5d366bb280e15eff94d80408   \n",
      "12223002         62  fb220c79fba6c75e71388cf126c95f07   \n",
      "12223003         62  fb220c79fba6c75e71388cf126c95f07   \n",
      "\n",
      "                                 driver_id                 time  day_of_week  \\\n",
      "0         9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4   \n",
      "1         3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2         448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3         ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4         424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "...                                    ...                  ...          ...   \n",
      "12222999  316842524eecb62b8492d9ebd2a272f4  2016-01-18 22:23:20            0   \n",
      "12223000                               NaN  2016-01-18 22:23:20            0   \n",
      "12223001  a13ad21fb0cd9106b32c8717e5abd464  2016-01-18 22:42:19            0   \n",
      "12223002  9ff0e5effae0d4e7c1d7e2fbb7456377  2016-01-18 23:15:35            0   \n",
      "12223003  9ff0e5effae0d4e7c1d7e2fbb7456377  2016-01-18 23:15:35            0   \n",
      "\n",
      "          poi_count  requests  answers_x  answers_y  \n",
      "0            653376       330          1        314  \n",
      "1            653376       330          1        314  \n",
      "2            653376       330          1        314  \n",
      "3            653376       330          1        314  \n",
      "4            653376       330          1        314  \n",
      "...             ...       ...        ...        ...  \n",
      "12222999       2988         3          1          2  \n",
      "12223000       2988         3          0          2  \n",
      "12223001       2988         1          1          1  \n",
      "12223002       2988         2          1          2  \n",
      "12223003       2988         2          1          2  \n",
      "\n",
      "[12223004 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "orderData['temp'] = 1\n",
    "orderData['answers'] = orderData['temp'].where(orderData['driver_id'].notnull(), 0)\n",
    "orderData = orderData.drop(['temp'], axis=1)\n",
    "groupedMergedData = orderData.groupby(['region_id','time_slot','day_of_week','weather','poi_count'])['answers'].agg('sum').reset_index()\n",
    "orderData = pd.merge(orderData,groupedMergedData, how='left' , on=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "print(orderData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = orderData.drop([\"answers_x\"], axis=1)\n",
    "orderData = orderData.rename(columns={\"answers_y\": \"answers\"})\n",
    "orderData.to_csv('mergedOrderData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          weather  time_slot        date                       region_hash  \\\n",
      "0               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "...           ...        ...         ...                               ...   \n",
      "12222999        2        135  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223000        2        135  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223001        2        137  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223002        2        140  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223003        2        140  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "\n",
      "          region_id                          order_id  \\\n",
      "0                 1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1                 1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2                 1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3                 1  74d98ad919a078a4c084098e2fdef219   \n",
      "4                 1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "...             ...                               ...   \n",
      "12222999         62  c43f09e0c3ee010bfd4c382a1bf5e009   \n",
      "12223000         62  a9fc1e22645810caa2f229c5250f4e60   \n",
      "12223001         62  02ae325b5d366bb280e15eff94d80408   \n",
      "12223002         62  fb220c79fba6c75e71388cf126c95f07   \n",
      "12223003         62  fb220c79fba6c75e71388cf126c95f07   \n",
      "\n",
      "                                 driver_id                 time  day_of_week  \\\n",
      "0         9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4   \n",
      "1         3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2         448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3         ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4         424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "...                                    ...                  ...          ...   \n",
      "12222999  316842524eecb62b8492d9ebd2a272f4  2016-01-18 22:23:20            0   \n",
      "12223000                               NaN  2016-01-18 22:23:20            0   \n",
      "12223001  a13ad21fb0cd9106b32c8717e5abd464  2016-01-18 22:42:19            0   \n",
      "12223002  9ff0e5effae0d4e7c1d7e2fbb7456377  2016-01-18 23:15:35            0   \n",
      "12223003  9ff0e5effae0d4e7c1d7e2fbb7456377  2016-01-18 23:15:35            0   \n",
      "\n",
      "          poi_count  requests  answers  supply_demand  \n",
      "0            653376       330      314             16  \n",
      "1            653376       330      314             16  \n",
      "2            653376       330      314             16  \n",
      "3            653376       330      314             16  \n",
      "4            653376       330      314             16  \n",
      "...             ...       ...      ...            ...  \n",
      "12222999       2988         3        2              1  \n",
      "12223000       2988         3        2              1  \n",
      "12223001       2988         1        1              0  \n",
      "12223002       2988         2        2              0  \n",
      "12223003       2988         2        2              0  \n",
      "\n",
      "[12223004 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "orderData['supply_demand'] = orderData['requests'] - orderData['answers']\n",
    "print(orderData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make rolling window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        region_hash  region_id\n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1\n",
      "1  f2c8c4bb99e6377d21de71275afd6cd2          2\n",
      "2  58c7a4888306d8ff3a641d1c0feccbe3          3\n",
      "3  b26a240205c852804ff8758628c0a86a          4\n",
      "4  4b9e4cf2fbdc8281b8a1f9f12b80ce4d          5\n"
     ]
    }
   ],
   "source": [
    "# read test data\n",
    "\n",
    "# read region Data\n",
    "regionTestData = pd.read_csv('./test_set/cluster_map/cluster_map', sep='\\t', names=['region_hash', 'region_id'],dtype={'region_hash': 'str', 'region_id': 'int'})\n",
    "print(regionTestData.head())\n",
    "#regionData.to_csv('regionData.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files read\n",
      "printing order data\n",
      "                           order_id                         driver_id  \\\n",
      "0  a51eaacf55aeeb106ac6cc429b8cd4f1  c34bbf688bd3008601bea47722023846   \n",
      "1  dbbf78e121305ff78578408fa80f0c3f  248955715350d5d9d2f0ee63c19760d9   \n",
      "2  87d9647097068af402aee1eec4efa2c1  248955715350d5d9d2f0ee63c19760d9   \n",
      "3  964f45562067302f486811fc24ec5f3f  756893197590002d87a87bfbee0f5f8b   \n",
      "4  d681c2fec2a3c4e1d55a073ee4a3a410  5d48fba0b0c71a0e776b5e30f042fe3e   \n",
      "\n",
      "                       passenger_id                 start_region_hash  \\\n",
      "0  62afaf3288e236b389af9cfdc5206415  62afaf3288e236b389af9cfdc5206415   \n",
      "1  d4ec2125aff74eded207d2d915ef682f  62afaf3288e236b389af9cfdc5206415   \n",
      "2  d4ec2125aff74eded207d2d915ef682f  62afaf3288e236b389af9cfdc5206415   \n",
      "3  929ec6c160e6f52c20a4217c7978f681  82cc4851f9e4faa4e54309f8bb73fd7c   \n",
      "4  91690261186ae5bee8f83808ea1e4a01  d4ec2125aff74eded207d2d915ef682f   \n",
      "\n",
      "                  time  \n",
      "0  2016-01-25 15:03:03  \n",
      "1  2016-01-25 19:19:10  \n",
      "2  2016-01-25 19:19:10  \n",
      "3  2016-01-25 21:16:19  \n",
      "4  2016-01-25 15:02:28  \n"
     ]
    }
   ],
   "source": [
    "# read order data\n",
    "dataTypes = {'order_id':'str', 'driver_id':'str', 'passenger_id':'str', 'start_region_hash':'str',  'time':'str'}\n",
    "orderDataPath = './test_set/order_data/'\n",
    "orderTestData = readMultipleData(orderDataPath,'test_order', ['order_id', 'driver_id', 'passenger_id', 'start_region_hash', 'time'], dataTypes,delimiter2=\",\")\n",
    "print(\"printing order data\")\n",
    "print(orderTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files read\n",
      "printing weather data\n",
      "                  time  weather  temperature  PM2.5\n",
      "0  2016-01-31 07:00:28        2          2.0   74.0\n",
      "1  2016-01-31 07:10:58        2          2.0   74.0\n",
      "2  2016-01-31 07:21:11        2          2.0   74.0\n",
      "3  2016-01-31 09:10:39        3          3.0   73.0\n",
      "4  2016-01-31 09:21:13        2          3.0   73.0\n"
     ]
    }
   ],
   "source": [
    "# read weather data\n",
    "dataTypes={'time':'str', 'weather':'int', 'temperature':'double', 'PM2.5':'double'}\n",
    "weatherTestDataPath = './test_set/weather_data/'\n",
    "weatherTestData = readMultipleData(weatherTestDataPath,'weather_data', ['time', 'weather', 'temperature', 'PM2.5'], dataTypes)\n",
    "print(\"printing weather data\")\n",
    "print(weatherTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date\n",
      "0        2         43  2016-01-31\n",
      "1        2         44  2016-01-31\n",
      "2        2         45  2016-01-31\n",
      "3        3         56  2016-01-31\n",
      "4        2         57  2016-01-31\n"
     ]
    }
   ],
   "source": [
    "#pre processing weather Test Data based on weather timeSlot \n",
    "weatherTestData['time_slot'] = weatherTestData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "weatherTestData['date'] = weatherTestData['time'].apply(extractDate)\n",
    "# weatherData['day_of_week'] = weatherData['time'].apply(extractDayOfWeek)\n",
    "weatherTestData = weatherTestData.drop(['temperature','PM2.5','time'], axis=1)\n",
    "print(weatherTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        region_hash  region_id  \\\n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "1  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "2  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "3  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "4  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "\n",
      "                           order_id                         driver_id  \\\n",
      "0  99569e90c43b4c35430edc2b9a1f1923  26c9d645c9af54321d7ae08f9a106c3b   \n",
      "1  23e6ef541ca6ce42a2249c5ea5deafec  dae11494cab3404a2ec811f92b012932   \n",
      "2  3aeeb610b6219045ccfdd667d5629c39  dae11494cab3404a2ec811f92b012932   \n",
      "3  e39b165d871fee8a8528e5ff0e13dbed  3dcc34744e2c8943dc24ad6fb23b38ad   \n",
      "4  cacbb2f2c4373ebe908cfe7200e2bf59  3dcc34744e2c8943dc24ad6fb23b38ad   \n",
      "\n",
      "                  time  time_slot  day_of_week        date  \n",
      "0  2016-01-25 21:18:42        128            0  2016-01-25  \n",
      "1  2016-01-25 13:17:59         80            0  2016-01-25  \n",
      "2  2016-01-25 13:17:59         80            0  2016-01-25  \n",
      "3  2016-01-25 21:16:52        128            0  2016-01-25  \n",
      "4  2016-01-25 21:16:52        128            0  2016-01-25  \n"
     ]
    }
   ],
   "source": [
    "orderTestData = pd.merge(regionTestData,orderTestData, how='inner', right_on='start_region_hash', left_on='region_hash')\n",
    "orderTestData['time_slot'] = orderTestData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "orderTestData['day_of_week'] = orderTestData['time'].apply(extractDayOfWeek)\n",
    "orderTestData['date'] = orderTestData['time'].apply(extractDate)\n",
    "orderTestData = orderTestData.drop(['passenger_id','start_region_hash'], axis=1)\n",
    "print(orderTestData.head())\n",
    "# regionData=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  fe8870d68b93d37803e9ea3d49687ae2   \n",
      "1          1  0f39a932da47b57b4afbe2364fbc62ff   \n",
      "2          1  4fe3b9a2c9f821119a3c02effe5aed62   \n",
      "3          1  bf388aae3be6483fc2f5783cdb36908e   \n",
      "4          1  dc273c2e10c1a647d9d4a83f3f6a69e9   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \n",
      "0  a5a682526cda6fca705304d32b17ea51  2016-01-31 07:02:45            6  \n",
      "1  d7dd58906cf6a53e7093d4d1c5255943  2016-01-31 07:08:43            6  \n",
      "2  2b98ba78105e3fe9c8d1b8b2592eed32  2016-01-31 07:03:43            6  \n",
      "3  9a3dd9ab0707f7787369d68da66a5a9e  2016-01-31 07:05:23            6  \n",
      "4  1ece5e0aeed86e23e6d1fc01fae18519  2016-01-31 07:02:57            6  \n"
     ]
    }
   ],
   "source": [
    "mergedTestOrderData = pd.merge(weatherTestData,orderTestData, how=\"inner\", on=['date','time_slot'])\n",
    "print(mergedTestOrderData.head())\n",
    "# orderData.to_csv('orderData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderTestData=None\n",
    "orderTestData = mergedTestOrderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region_id  poi_count\n",
      "0          1     653376\n",
      "1          2     343537\n",
      "2          3      31125\n",
      "3          4     187829\n",
      "4          5      27888\n"
     ]
    }
   ],
   "source": [
    "# read POI Data\n",
    "poiDataStr = {\n",
    "    'region_hash':[],\n",
    "    'poi_class':[]\n",
    "}\n",
    "with open('./test_set/poi_data/poi_data','r') as fileToRead:\n",
    "    for line in fileToRead:\n",
    "        line = line.strip()\n",
    "        columns = line.split('\\t')\n",
    "        poiDataStr['region_hash'].append(columns[0])\n",
    "        remData = columns[1:]\n",
    "        poiDataStr['poi_class'].append(remData)\n",
    "        \n",
    "poiTestData = pd.DataFrame(poiDataStr,columns=['region_hash','poi_class'])\n",
    "poiTestData['poi_count'] = poiTestData['poi_class'].apply(extractNumberOfPOI)\n",
    "poiTestData = pd.merge(regionTestData,poiTestData, how='inner', on='region_hash')\n",
    "poiTestData = poiTestData.drop(['region_hash'], axis=1)\n",
    "poiTestData = poiTestData.drop(['poi_class'], axis=1)\n",
    "print(poiTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  fe8870d68b93d37803e9ea3d49687ae2   \n",
      "1          1  0f39a932da47b57b4afbe2364fbc62ff   \n",
      "2          1  4fe3b9a2c9f821119a3c02effe5aed62   \n",
      "3          1  bf388aae3be6483fc2f5783cdb36908e   \n",
      "4          1  dc273c2e10c1a647d9d4a83f3f6a69e9   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  a5a682526cda6fca705304d32b17ea51  2016-01-31 07:02:45            6   \n",
      "1  d7dd58906cf6a53e7093d4d1c5255943  2016-01-31 07:08:43            6   \n",
      "2  2b98ba78105e3fe9c8d1b8b2592eed32  2016-01-31 07:03:43            6   \n",
      "3  9a3dd9ab0707f7787369d68da66a5a9e  2016-01-31 07:05:23            6   \n",
      "4  1ece5e0aeed86e23e6d1fc01fae18519  2016-01-31 07:02:57            6   \n",
      "\n",
      "   poi_count  \n",
      "0     653376  \n",
      "1     653376  \n",
      "2     653376  \n",
      "3     653376  \n",
      "4     653376  \n"
     ]
    }
   ],
   "source": [
    "orderTestData = pd.merge(orderTestData,poiTestData, how=\"inner\", on='region_id')\n",
    "orderTestData = orderTestData.drop([\"poi_count_x\"],axis=1)\n",
    "orderTestData = orderTestData.rename(columns={\"poi_count_y\": \"poi_count\"})\n",
    "print(orderTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  fe8870d68b93d37803e9ea3d49687ae2   \n",
      "1          1  0f39a932da47b57b4afbe2364fbc62ff   \n",
      "2          1  4fe3b9a2c9f821119a3c02effe5aed62   \n",
      "3          1  bf388aae3be6483fc2f5783cdb36908e   \n",
      "4          1  dc273c2e10c1a647d9d4a83f3f6a69e9   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  a5a682526cda6fca705304d32b17ea51  2016-01-31 07:02:45            6   \n",
      "1  d7dd58906cf6a53e7093d4d1c5255943  2016-01-31 07:08:43            6   \n",
      "2  2b98ba78105e3fe9c8d1b8b2592eed32  2016-01-31 07:03:43            6   \n",
      "3  9a3dd9ab0707f7787369d68da66a5a9e  2016-01-31 07:05:23            6   \n",
      "4  1ece5e0aeed86e23e6d1fc01fae18519  2016-01-31 07:02:57            6   \n",
      "\n",
      "   poi_count  requests_x  requests_y  \n",
      "0     653376           1          37  \n",
      "1     653376           1          37  \n",
      "2     653376           1          37  \n",
      "3     653376           1          37  \n",
      "4     653376           1          37  \n"
     ]
    }
   ],
   "source": [
    "# print(mergedDataCSV)\n",
    "orderTestData['requests'] = 1\n",
    "# print(orderData.head())\n",
    "groupedTestMergedData = orderTestData.groupby(['region_id','time_slot','day_of_week','weather','poi_count'])['requests'].agg('sum').reset_index()\n",
    "# groupedMergedData = groupedMergedData.drop(['date','region_hash','order_id','driver_id','time'], axis=1)\n",
    "orderTestData = pd.merge(orderTestData,groupedTestMergedData, how='left' , on=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "print(orderTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  fe8870d68b93d37803e9ea3d49687ae2   \n",
      "1          1  0f39a932da47b57b4afbe2364fbc62ff   \n",
      "2          1  4fe3b9a2c9f821119a3c02effe5aed62   \n",
      "3          1  bf388aae3be6483fc2f5783cdb36908e   \n",
      "4          1  dc273c2e10c1a647d9d4a83f3f6a69e9   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  a5a682526cda6fca705304d32b17ea51  2016-01-31 07:02:45            6   \n",
      "1  d7dd58906cf6a53e7093d4d1c5255943  2016-01-31 07:08:43            6   \n",
      "2  2b98ba78105e3fe9c8d1b8b2592eed32  2016-01-31 07:03:43            6   \n",
      "3  9a3dd9ab0707f7787369d68da66a5a9e  2016-01-31 07:05:23            6   \n",
      "4  1ece5e0aeed86e23e6d1fc01fae18519  2016-01-31 07:02:57            6   \n",
      "\n",
      "   poi_count  requests_x  requests  \n",
      "0     653376           1        37  \n",
      "1     653376           1        37  \n",
      "2     653376           1        37  \n",
      "3     653376           1        37  \n",
      "4     653376           1        37  \n"
     ]
    }
   ],
   "source": [
    "orderTestData = orderTestData.drop([\"requests_x\"], axis=1)\n",
    "orderTestData = orderTestData.rename(columns={\"requests_y\": \"requests\"})\n",
    "print(orderTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to calculate gap(i,j) = req(i,j) - supply(i,j)\n",
    "# # req(i,j) is for region i and timeslot j \n",
    "# # ith region will be from from start_region_hash and jth timeslot will be calculated from time\n",
    "# def getRegionID(regionHash):\n",
    "#     regionID = -1\n",
    "#     for i in range(len(regionData)):\n",
    "#         if regionHash == regionData['region_hash'][i]:\n",
    "#             regionID = regionData['region_id'][i]\n",
    "#     return regionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergedData = None # here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop order_id, driver_id, passenger_id, dest_region_hash\n",
    "# mergedData = orderData.drop(['order_id', 'passenger_id', 'dest_region_hash'], axis=1)\n",
    "# print(\"dropped order_id, passenger_id, dest_region_hash\")\n",
    "#  merge order data with region data on start_region_hash with region_hash\n",
    "# mergedData = pd.merge(regionData,mergedData, how='left', right_on='start_region_hash', left_on='region_hash')\n",
    "# print(\"merged order data and region data based on region\")\n",
    "\n",
    "# mergedData = mergedData.drop(['region_hash','start_region_hash'], axis=1)\n",
    "# print(\"dropped region_hash, start_region_hash\")\n",
    "# # reduce time to time slot and update time column\n",
    "# mergedData['time'] = mergedData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "# print(\"reduced time to time slot 1 to 144\")\n",
    "# rename time to time_slot\n",
    "# mergedData.rename(columns={'time':'time_slot'}, inplace=True)\n",
    "# # append column for day of week into mergedData\n",
    "# mergedData['day_of_week'] = orderData['time'].apply(extractDayOfWeek)\n",
    "# print(\"appended day_of_week column to data\")\n",
    "# now we have mergedData with region_id, price, time, day_of_week\n",
    "# print(\"printing merged data\")\n",
    "# print(mergedData)\n",
    "\n",
    "# writing to mergedData.csv for quick access\n",
    "# orderData.to_csv('mergedData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mergedData.csv\n",
    "# mergedDataCSV = pd.read_csv('mergedData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mergedDataCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to get req(i,j) we can do that by counting the number of orders for region i and timeslot j\n",
    "# def getRequest(i,j): # i is region id and j is timeslot\n",
    "#     global orderData\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "#     requests = 0\n",
    "#     for row in range(len(orderData)):\n",
    "#         currentRegionID = getRegionID(orderData['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(orderData['time'][row],False)\n",
    "#         if currentRegionID == i and currentTimeSlot == j:\n",
    "#             requests += 1\n",
    "#         progressBarInit.update(1)\n",
    "#     progressBarInit.close()\n",
    "#     return requests\n",
    "\n",
    "# print(\"Printing request for 1st region and 1st timeslot\")\n",
    "# print(getRequest(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def dateToIndex(date):\n",
    "# #     index = 0\n",
    "    \n",
    "# #     return index\n",
    "\n",
    "# def getAllRequestAndSupply(): # need to filter by date \n",
    "#     global orderData\n",
    "#     global regionData\n",
    "#     global NUM_TIME_SLOTS\n",
    "#     global NUM_DAYS_IN_DATA\n",
    "#     numberOfRegions = len(regionData)\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "#     # 3D requests array requests[i][j][k] is number of requests --> date i ,region j, timeslot k\n",
    "#     # requests = [[[0 for k in range(NUM_TIME_SLOTS)] for j in range(numberOfRegions)] for i in range(NUM_DAYS_IN_DATA)]\n",
    "#     # supply = [[[0 for k in range(NUM_TIME_SLOTS)] for j in range(numberOfRegions)] for i in range(NUM_DAYS_IN_DATA)]\n",
    "#     requests = [[0 for j in range(NUM_TIME_SLOTS)] for i in range(numberOfRegions)]\n",
    "#     supply = [[0 for j in range(NUM_TIME_SLOTS)] for i in range(numberOfRegions)]\n",
    "#     for row in range(len(orderData)):\n",
    "#         currentRegionID = getRegionID(orderData['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(orderData['time'][row],False)\n",
    "#         # date = orderData['time'][row].split(' ')[0]\n",
    "        \n",
    "#         if currentRegionID < 0:\n",
    "#             print(f\"Region not found for {orderData['start_region_hash'][row]}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot < 0:\n",
    "#             print(f\"Time slot not found for {orderData['time'][row]}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentRegionID > numberOfRegions:\n",
    "#             print(f\"Region id {currentRegionID} is greater than number of regions {numberOfRegions}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot > NUM_TIME_SLOTS:\n",
    "#             print(f\"Time slot {currentTimeSlot} is greater than number of time slots {NUM_TIME_SLOTS}\")\n",
    "#             print(f\"Time: {orderData['time'][row]}\")\n",
    "#             print(f\"Row: {row}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot == 0:\n",
    "#             print(f\"Time slot is 0 for {orderData['time'][row]}\")\n",
    "#             print(f\"Row: {row}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         # requests[currentDate][currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         requests[currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         if type(orderData['driver_id'][row]) == str:\n",
    "#             supply[currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#             # supply[currentDate][currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         progressBarInit.update(1)\n",
    "#     progressBarInit.close()\n",
    "#     return (requests,supply)\n",
    "\n",
    "# print(\"Printing request and supply regions d(i) and timeslots t(j)\")\n",
    "# (request,supply) = getAllRequestAndSupply()\n",
    "# print(request)\n",
    "# print(supply) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npRequest = np.array(request)\n",
    "# npSupply = np.array(supply)\n",
    "# np.savetxt('request.csv', npRequest, delimiter=',')\n",
    "# np.savetxt('supply.csv', npSupply, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to get req(i,j) we can do that by counting the number of orders for region i and timeslot j\n",
    "# # concurrentI =0\n",
    "# # concurrentJ =0\n",
    "# def getRequestMulti(data, i, j,lowerIndex,upperIndex):\n",
    "#     # (orderData, i, j,lowerIndex,upperIndex) = arguments\n",
    "#     numberOfIterations = upperIndex - lowerIndex\n",
    "#     currentPID = mp.current_process()._identity[0]-1\n",
    "#     # logging.info(f\"process {currentPID}\")\n",
    "#     print(f\"Number of lines of data: {numberOfIterations} for process {currentPID}\")\n",
    "#     # progressBarInit = tqdm(total=numberOfIterations, desc=f\"Calculating requests {currentPID}\", unit=\" lines\")\n",
    "#     lowerIndex = lowerIndex[currentPID]\n",
    "#     upperIndex = upperIndex[currentPID]\n",
    "#     requests = 0\n",
    "#     for row in range(lowerIndex,upperIndex):\n",
    "#         currentRegionID = getRegionID(data['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(data['time'][row],False)\n",
    "#         if currentRegionID == i and currentTimeSlot == j:\n",
    "#             requests += 1\n",
    "#         # progressBarInit.update(1)\n",
    "#     # progressBarInit.close()\n",
    "#     return requests\n",
    "\n",
    "# def getRequestHelper(i,j): # i is region id and j is timeslot\n",
    "#     global orderData\n",
    "#     # global concurrentI\n",
    "#     # global concurrentJ\n",
    "#     # concurrentJ = j\n",
    "#     # concurrentI = i\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     # logging.basicConfig(level=logging.INFO,filename='worker.log', filemode='w')\n",
    "#     # console_handler = logging.StreamHandler()\n",
    "#     # logging.getLogger().addHandler(console_handler)\n",
    "#     # print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     # progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "    \n",
    "#     numberOfProcessesToRun = mp.cpu_count()\n",
    "#     print(f\"CPUs: {numberOfProcessesToRun}\")\n",
    "#     multiProcessingPool = mp.Pool(numberOfProcessesToRun)\n",
    "#     upperIndex = []\n",
    "#     lowerIndex = []\n",
    "#     for i in range(numberOfProcessesToRun):\n",
    "#         lowerval = i*numberOfIterations//numberOfProcessesToRun\n",
    "#         upperVal = (i+1)*numberOfIterations//numberOfProcessesToRun\n",
    "#         lowerIndex.append(lowerval)\n",
    "#         upperIndex.append(upperVal)\n",
    "#     print(\"Here\")\n",
    "#     # argumentsToPass = (orderData, i, j,lowerIndex, upperIndex)\n",
    "#     requests = multiProcessingPool.starmap(getRequestMulti, [(orderData, i, j,lowerIndex, upperIndex)])\n",
    "#     requests = sum(requests)\n",
    "#     multiProcessingPool.close()\n",
    "#     multiProcessingPool.join()\n",
    "#     return requests\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Printing request for 1st region and 1st timeslot\")\n",
    "# print(getRequestHelper(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
