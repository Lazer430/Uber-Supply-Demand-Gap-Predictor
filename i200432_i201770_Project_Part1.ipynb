{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install tqdm\n",
    "# !pip install sklearn\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is dev branch\n",
    "import datetime\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "NUM_TIME_SLOTS = 144\n",
    "NUM_DAYS_IN_DATA = 0"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 4,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 hours is divided into 144 slots where each slot is 10 mins long\n",
    "def calculateTimeSlot(time,printValue=True):\n",
    "    global NUM_TIME_SLOTS\n",
    "    dateTime = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    timePart = dateTime.time()\n",
    "    timeInMinutes = (timePart.hour * 60) + timePart.minute + (timePart.second/60) + 1\n",
    "    timeSlot = timeInMinutes/10\n",
    "    roundedTimeSlot = math.ceil(timeSlot)\n",
    "    if roundedTimeSlot > NUM_TIME_SLOTS:\n",
    "        roundedTimeSlot -= 1\n",
    "    if printValue==True:\n",
    "        print(f\"time: {time} timeInMinutes: {timeInMinutes} timeSlot: {roundedTimeSlot}\")\n",
    "    return int(roundedTimeSlot)\n",
    "\n",
    "def extractDayOfWeek(time):\n",
    "    d = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    return d.weekday()\n",
    "\n",
    "def extractDate(time):\n",
    "    d = datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    return d.date()\n",
    "\n",
    "print(type(extractDate('2019-01-01 00:00:00')))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNumberOfPOI(poiArray):\n",
    "    poiCount = 0\n",
    "    for poiEntry in poiArray:\n",
    "        poiEntry = poiEntry + ':'\n",
    "        divisions = poiEntry.split(\":\")\n",
    "        poiCount += int(divisions[1])\n",
    "    return poiCount\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 15,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMultipleData(path,fileNamePrefix,headerNames,dataTypes,delimiter2=\"\\t\"):\n",
    "    global NUM_DAYS_IN_DATA\n",
    "    filesToExplore = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.startswith(fileNamePrefix):\n",
    "            filesToExplore.append(file)\n",
    "            # print(f\"{file} read\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    print(f\"{len(filesToExplore)} files read\")\n",
    "    if fileNamePrefix == 'order':\n",
    "        NUM_DAYS_IN_DATA = len(filesToExplore)\n",
    "    \n",
    "    readData = []\n",
    "    for files in filesToExplore:\n",
    "        fileRead = pd.read_csv(path + files, sep=delimiter2, names=headerNames,dtype=dataTypes)\n",
    "        readData.append(fileRead)\n",
    "\n",
    "    readData = pd.concat(readData, ignore_index=True)\n",
    "    return readData"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "# now region Data\n",
    "regionData = pd.read_csv('./training_data/cluster_map/cluster_map', sep='\\t', names=['region_hash', 'region_id'],dtype={'region_hash': 'str', 'region_id': 'int'})\n",
    "# print(regionData.head())\n",
    "regionData.to_csv('regionData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 6,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "# read order data\n",
    "dataTypes = {'order_id':'str', 'driver_id':'str', 'passenger_id':'str', 'start_region_hash':'str', 'dest_region_hash':'str', 'price':'double', 'time':'str'}\n",
    "orderDataPath = './training_data/order_data/'\n",
    "orderData = readMultipleData(orderDataPath,'order', ['order_id', 'driver_id', 'passenger_id', 'start_region_hash', 'dest_region_hash', 'price', 'time'], dataTypes)\n",
    "print(\"printing order data\")\n",
    "# print(orderData.head())\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 7,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "# read weather data\n",
    "dataTypes={'time':'str', 'weather':'int', 'temperature':'double', 'PM2.5':'double'}\n",
    "weatherDataPath = './training_data/weather_data/'\n",
    "weatherData = readMultipleData(weatherDataPath,'weather', ['time', 'weather', 'temperature', 'PM2.5'], dataTypes)\n",
    "print(\"printing weather data\")\n",
    "# print(weatherData.head())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 8,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherData['time_slot'] = weatherData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "weatherData['date'] = weatherData['time'].apply(extractDate)\n",
    "# weatherData['day_of_week'] = weatherData['time'].apply(extractDayOfWeek)\n",
    "weatherData = weatherData.drop(['temperature','PM2.5','time'], axis=1)\n",
    "print(weatherData.head())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        region_hash  region_id  \\\n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "1  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "2  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "3  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "4  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "\n",
      "                           order_id                         driver_id  \\\n",
      "0  a21153d78caad6117ae7a7c1e456fe49  5a9fa443a4824c8d8ec0c210dfe57774   \n",
      "1  359f767cb703721f07e59f839a55230d  cd766c70d6db45140cd39c319db65057   \n",
      "2  d0b97274f30a8b9c02d483581e975ad4  0359fc335d238c6206703d1d7e3620c8   \n",
      "3  b9004db345b0b097c4f6daa66c7d2e6e  c18455b7ad9444ad9b44d534182aeb9f   \n",
      "4  21a9c02f774ff068b2165f715378f9f7  611ae91b57a0b0d458eb96455f50a6cb   \n",
      "\n",
      "                  time  time_slot  day_of_week        date  \n",
      "0  2016-01-04 16:10:14         98            0  2016-01-04  \n",
      "1  2016-01-04 18:41:03        113            0  2016-01-04  \n",
      "2  2016-01-04 10:22:37         63            0  2016-01-04  \n",
      "3  2016-01-04 07:06:46         43            0  2016-01-04  \n",
      "4  2016-01-04 18:37:12        112            0  2016-01-04  \n"
     ]
    }
   ],
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "source": [
    "orderData = pd.merge(regionData,orderData, how='left', right_on='start_region_hash', left_on='region_hash')\n",
    "orderData['time_slot'] = orderData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "orderData['day_of_week'] = orderData['time'].apply(extractDayOfWeek)\n",
    "orderData['date'] = orderData['time'].apply(extractDate)\n",
    "orderData = orderData.drop(['passenger_id', 'dest_region_hash','start_region_hash','price'], axis=1)\n",
    "print(orderData.head())\n",
    "# regionData=None"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4  \n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4  \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4  \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4  \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4  \n"
     ]
    }
   ],
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "source": [
    "mergedOrderData = pd.merge(weatherData,orderData, how=\"inner\", on=['date','time_slot'])\n",
    "print(mergedOrderData.head())\n",
    "# orderData.to_csv('orderData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData=None\n",
    "orderData = mergedOrderData\n",
    "# orderData.to_csv('mergedOrderData.csv',index=False)\n",
    "# type(orderData['driver_id'][4])==float"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 12,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = pd.read_csv('mergedOrderData.csv')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 13,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "# read POI Data\n",
    "poiDataStr = {\n",
    "    'region_hash':[],\n",
    "    'poi_class':[]\n",
    "}\n",
    "with open('./training_data/poi_data/poi_data','r') as fileToRead:\n",
    "    for line in fileToRead:\n",
    "        line = line.strip()\n",
    "        columns = line.split('\\t')\n",
    "        poiDataStr['region_hash'].append(columns[0])\n",
    "        remData = columns[1:]\n",
    "        poiDataStr['poi_class'].append(remData)\n",
    "        \n",
    "poiData = pd.DataFrame(poiDataStr,columns=['region_hash','poi_class'])\n",
    "poiData['poi_count'] = poiData['poi_class'].apply(extractNumberOfPOI)\n",
    "poiData = pd.merge(regionData,poiData, how='inner', on='region_hash')\n",
    "poiData = poiData.drop(['region_hash'], axis=1)\n",
    "poiData = poiData.drop(['poi_class'], axis=1)\n",
    "print(poiData.head())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4   \n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "\n",
      "   poi_count  \n",
      "0     653376  \n",
      "1     653376  \n",
      "2     653376  \n",
      "3     653376  \n",
      "4     653376  \n"
     ]
    }
   ],
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "source": [
    "orderData = pd.merge(orderData,poiData, how=\"inner\", on='region_id')\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4   \n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "\n",
      "   poi_count  requests_x  requests_y  \n",
      "0     653376           1         330  \n",
      "1     653376           1         330  \n",
      "2     653376           1         330  \n",
      "3     653376           1         330  \n",
      "4     653376           1         330  \n"
     ]
    }
   ],
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "source": [
    "# print(mergedDataCSV)\n",
    "orderData['requests'] = 1\n",
    "# print(orderData.head())\n",
    "groupedMergedData = orderData.groupby(['region_id','time_slot','day_of_week','weather','poi_count'])['requests'].agg('sum').reset_index()\n",
    "# groupedMergedData = groupedMergedData.drop(['date','region_hash','order_id','driver_id','time'], axis=1)\n",
    "orderData = pd.merge(orderData,groupedMergedData, how='left' , on=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1          1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2          1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3          1  74d98ad919a078a4c084098e2fdef219   \n",
      "4          1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4   \n",
      "1  3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2  448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3  ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4  424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "\n",
      "   poi_count  requests  \n",
      "0     653376       330  \n",
      "1     653376       330  \n",
      "2     653376       330  \n",
      "3     653376       330  \n",
      "4     653376       330  \n"
     ]
    }
   ],
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "source": [
    "orderData = orderData.drop([\"requests_x\"], axis=1)\n",
    "orderData = orderData.rename(columns={\"requests_y\": \"requests\"})\n",
    "print(orderData.head())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          weather  time_slot        date                       region_hash  \\\n",
      "0               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "...           ...        ...         ...                               ...   \n",
      "12222999        2        135  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223000        2        135  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223001        2        137  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223002        2        140  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223003        2        140  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "\n",
      "          region_id                          order_id  \\\n",
      "0                 1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1                 1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2                 1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3                 1  74d98ad919a078a4c084098e2fdef219   \n",
      "4                 1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "...             ...                               ...   \n",
      "12222999         62  c43f09e0c3ee010bfd4c382a1bf5e009   \n",
      "12223000         62  a9fc1e22645810caa2f229c5250f4e60   \n",
      "12223001         62  02ae325b5d366bb280e15eff94d80408   \n",
      "12223002         62  fb220c79fba6c75e71388cf126c95f07   \n",
      "12223003         62  fb220c79fba6c75e71388cf126c95f07   \n",
      "\n",
      "                                 driver_id                 time  day_of_week  \\\n",
      "0         9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4   \n",
      "1         3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2         448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3         ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4         424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "...                                    ...                  ...          ...   \n",
      "12222999  316842524eecb62b8492d9ebd2a272f4  2016-01-18 22:23:20            0   \n",
      "12223000                               NaN  2016-01-18 22:23:20            0   \n",
      "12223001  a13ad21fb0cd9106b32c8717e5abd464  2016-01-18 22:42:19            0   \n",
      "12223002  9ff0e5effae0d4e7c1d7e2fbb7456377  2016-01-18 23:15:35            0   \n",
      "12223003  9ff0e5effae0d4e7c1d7e2fbb7456377  2016-01-18 23:15:35            0   \n",
      "\n",
      "          poi_count  requests  answers_x  answers_y  \n",
      "0            653376       330          1        314  \n",
      "1            653376       330          1        314  \n",
      "2            653376       330          1        314  \n",
      "3            653376       330          1        314  \n",
      "4            653376       330          1        314  \n",
      "...             ...       ...        ...        ...  \n",
      "12222999       2988         3          1          2  \n",
      "12223000       2988         3          0          2  \n",
      "12223001       2988         1          1          1  \n",
      "12223002       2988         2          1          2  \n",
      "12223003       2988         2          1          2  \n",
      "\n",
      "[12223004 rows x 13 columns]\n"
     ]
    }
   ],
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "source": [
    "orderData['temp'] = 1\n",
    "orderData['answers'] = orderData['temp'].where(orderData['driver_id'].notnull(), 0)\n",
    "orderData = orderData.drop(['temp'], axis=1)\n",
    "groupedMergedData = orderData.groupby(['region_id','time_slot','day_of_week','weather','poi_count'])['answers'].agg('sum').reset_index()\n",
    "orderData = pd.merge(orderData,groupedMergedData, how='left' , on=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "print(orderData)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 18,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = orderData.drop([\"answers_x\"], axis=1)\n",
    "orderData = orderData.rename(columns={\"answers_y\": \"answers\"})\n",
    "orderData.to_csv('mergedOrderData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderData = pd.read_csv('mergedOrderData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
=======
   "execution_count": 19,
>>>>>>> dbd7e287cd913803bfa3b9f283c1728706e0a47a
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          weather  time_slot        date                       region_hash  \\\n",
      "0               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4               1          1  2016-01-01  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "...           ...        ...         ...                               ...   \n",
      "12222999        2        135  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223000        2        135  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223001        2        137  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223002        2        140  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "12223003        2        140  2016-01-18  a735449c5c09df639c35a7d61fad3ee5   \n",
      "\n",
      "          region_id                          order_id  \\\n",
      "0                 1  df1dc94f51fec68d3116e4b6bd8480a9   \n",
      "1                 1  e245a3caefc7f1834c27e77899b40beb   \n",
      "2                 1  20acf3478835a0e13f81f3100954b5e3   \n",
      "3                 1  74d98ad919a078a4c084098e2fdef219   \n",
      "4                 1  b5425edd2549e13e42df1f78e347a4b0   \n",
      "...             ...                               ...   \n",
      "12222999         62  c43f09e0c3ee010bfd4c382a1bf5e009   \n",
      "12223000         62  a9fc1e22645810caa2f229c5250f4e60   \n",
      "12223001         62  02ae325b5d366bb280e15eff94d80408   \n",
      "12223002         62  fb220c79fba6c75e71388cf126c95f07   \n",
      "12223003         62  fb220c79fba6c75e71388cf126c95f07   \n",
      "\n",
      "                                 driver_id                 time  day_of_week  \\\n",
      "0         9e1015af3e2006d7d0ca07d6440f1969  2016-01-01 00:05:01            4   \n",
      "1         3fdc66ca318f1ca0afa45d39f5a870a7  2016-01-01 00:06:34            4   \n",
      "2         448a2dd8f89301b0a963829e294482cb  2016-01-01 00:08:49            4   \n",
      "3         ac143220ecb852f148ae3b13d3cda82d  2016-01-01 00:08:34            4   \n",
      "4         424d575e06444681e4a80827450cccf5  2016-01-01 00:08:34            4   \n",
      "...                                    ...                  ...          ...   \n",
      "12222999  316842524eecb62b8492d9ebd2a272f4  2016-01-18 22:23:20            0   \n",
      "12223000                               NaN  2016-01-18 22:23:20            0   \n",
      "12223001  a13ad21fb0cd9106b32c8717e5abd464  2016-01-18 22:42:19            0   \n",
      "12223002  9ff0e5effae0d4e7c1d7e2fbb7456377  2016-01-18 23:15:35            0   \n",
      "12223003  9ff0e5effae0d4e7c1d7e2fbb7456377  2016-01-18 23:15:35            0   \n",
      "\n",
      "          poi_count  requests  answers  supply_demand  \n",
      "0            653376       330      314             16  \n",
      "1            653376       330      314             16  \n",
      "2            653376       330      314             16  \n",
      "3            653376       330      314             16  \n",
      "4            653376       330      314             16  \n",
      "...             ...       ...      ...            ...  \n",
      "12222999       2988         3        2              1  \n",
      "12223000       2988         3        2              1  \n",
      "12223001       2988         1        1              0  \n",
      "12223002       2988         2        2              0  \n",
      "12223003       2988         2        2              0  \n",
      "\n",
      "[12223004 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "orderData['supply_demand'] = orderData['requests'] - orderData['answers']\n",
    "print(orderData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=5, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=5, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply model here\n",
    "AImodel = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=0)\n",
    "X = orderData[['region_id','time_slot','day_of_week','weather','poi_count']]\n",
    "Y = orderData['supply_demand']\n",
    "AImodel.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.65673643]\n",
      "0.4313027409787012\n"
     ]
    }
   ],
   "source": [
    "tempData = pd.DataFrame([[1,5,3,7,20000]],columns=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "# tempData = pd.DataFrame([[1,5,3,7,20000]],columns=['region_id','time_slot'])\n",
    "print(AImodel.predict(tempData))\n",
    "mse = mean_squared_error([28], AImodel.predict(tempData))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make rolling window function\n",
    "def rollTheWindow(data,windowSize):\n",
    "    datasetLength = len(data)\n",
    "    listOfPredictions = []\n",
    "    numberOfWindows = datasetLength//windowSize\n",
    "    for i in range(numberOfWindows):\n",
    "        rollingWindow = []\n",
    "        lowerLimit = i\n",
    "        upperLimit = i+windowSize\n",
    "        rollingWindow.append(data[lowerLimit:upperLimit])\n",
    "        rollingWindow = pd.concat(rollingWindow)\n",
    "        X_WINDOW_INPUT = rollingWindow[['region_id','time_slot','day_of_week','weather','poi_count']]\n",
    "        Y_WINDOW_OUTPUT = rollingWindow['supply_demand']\n",
    "        currentPrediction = AImodel.predict(X_WINDOW_INPUT)\n",
    "        meanSqError = mean_squared_error(Y_WINDOW_OUTPUT, currentPrediction)\n",
    "        print(f\"Prediction for window [{lowerLimit},{upperLimit}]={currentPrediction} MSE={meanSqError}\")\n",
    "        predictionTuple = (lowerLimit,upperLimit,currentPrediction,meanSqError)\n",
    "        listOfPredictions.append(predictionTuple)\n",
    "        i = upperLimit + 1\n",
    "    return listOfPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for window [0,1]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [1,2]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [2,3]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [3,4]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [4,5]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [5,6]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [6,7]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [7,8]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [8,9]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [9,10]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [10,11]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [11,12]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [12,13]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [13,14]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [14,15]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [15,16]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [16,17]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [17,18]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [18,19]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [19,20]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [20,21]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [21,22]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [22,23]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [23,24]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [24,25]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [25,26]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [26,27]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [27,28]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [28,29]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [29,30]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [30,31]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [31,32]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [32,33]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [33,34]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [34,35]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [35,36]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [36,37]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [37,38]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [38,39]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [39,40]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [40,41]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [41,42]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [42,43]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [43,44]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [44,45]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [45,46]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [46,47]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [47,48]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [48,49]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [49,50]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [50,51]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [51,52]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [52,53]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [53,54]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [54,55]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [55,56]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [56,57]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [57,58]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [58,59]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [59,60]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [60,61]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [61,62]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [62,63]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [63,64]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [64,65]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [65,66]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [66,67]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [67,68]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [68,69]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [69,70]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [70,71]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [71,72]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [72,73]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [73,74]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [74,75]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [75,76]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [76,77]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [77,78]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [78,79]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [79,80]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [80,81]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [81,82]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [82,83]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [83,84]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [84,85]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [85,86]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [86,87]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [87,88]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [88,89]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [89,90]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [90,91]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [91,92]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [92,93]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [93,94]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [94,95]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [95,96]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [96,97]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [97,98]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [98,99]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [99,100]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [100,101]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [101,102]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [102,103]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [103,104]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [104,105]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [105,106]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [106,107]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [107,108]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [108,109]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [109,110]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [110,111]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [111,112]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [112,113]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [113,114]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [114,115]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [115,116]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [116,117]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [117,118]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [118,119]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [119,120]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [120,121]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [121,122]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [122,123]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [123,124]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [124,125]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [125,126]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [126,127]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [127,128]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [128,129]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [129,130]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [130,131]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [131,132]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [132,133]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [133,134]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [134,135]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [135,136]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [136,137]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [137,138]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [138,139]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [139,140]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [140,141]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [141,142]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [142,143]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [143,144]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [144,145]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [145,146]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [146,147]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [147,148]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [148,149]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [149,150]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [150,151]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [151,152]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [152,153]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [153,154]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [154,155]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [155,156]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [156,157]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [157,158]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [158,159]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [159,160]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [160,161]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [161,162]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [162,163]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [163,164]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [164,165]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [165,166]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [166,167]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [167,168]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [168,169]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [169,170]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [170,171]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [171,172]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [172,173]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [173,174]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [174,175]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [175,176]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [176,177]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [177,178]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [178,179]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [179,180]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [180,181]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [181,182]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [182,183]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [183,184]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [184,185]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [185,186]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [186,187]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [187,188]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [188,189]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [189,190]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [190,191]=[124.21251258] MSE=11709.947878351923\n",
      "Prediction for window [191,192]=[124.21251258] MSE=11709.947878351923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rollTheWindow(orderData,\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[29], line 14\u001b[0m, in \u001b[0;36mrollTheWindow\u001b[1;34m(data, windowSize)\u001b[0m\n\u001b[0;32m     12\u001b[0m X_WINDOW_INPUT \u001b[39m=\u001b[39m rollingWindow[[\u001b[39m'\u001b[39m\u001b[39mregion_id\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtime_slot\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mday_of_week\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mweather\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mpoi_count\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     13\u001b[0m Y_WINDOW_OUTPUT \u001b[39m=\u001b[39m rollingWindow[\u001b[39m'\u001b[39m\u001b[39msupply_demand\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m currentPrediction \u001b[39m=\u001b[39m AImodel\u001b[39m.\u001b[39;49mpredict(X_WINDOW_INPUT)\n\u001b[0;32m     15\u001b[0m meanSqError \u001b[39m=\u001b[39m mean_squared_error(Y_WINDOW_OUTPUT, currentPrediction)\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrediction for window [\u001b[39m\u001b[39m{\u001b[39;00mlowerLimit\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mupperLimit\u001b[39m}\u001b[39;00m\u001b[39m]=\u001b[39m\u001b[39m{\u001b[39;00mcurrentPrediction\u001b[39m}\u001b[39;00m\u001b[39m MSE=\u001b[39m\u001b[39m{\u001b[39;00mmeanSqError\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:994\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[39m# Parallel loop\u001b[39;00m\n\u001b[0;32m    993\u001b[0m lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[1;32m--> 994\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, require\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msharedmem\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\n\u001b[0;32m    995\u001b[0m     delayed(_accumulate_prediction)(e\u001b[39m.\u001b[39;49mpredict, X, [y_hat], lock)\n\u001b[0;32m    996\u001b[0m     \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[0;32m    997\u001b[0m )\n\u001b[0;32m    999\u001b[0m y_hat \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_)\n\u001b[0;32m   1001\u001b[0m \u001b[39mreturn\u001b[39;00m y_hat\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:650\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[0;32m    644\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[39m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \n\u001b[0;32m    647\u001b[0m \u001b[39m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[39m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 650\u001b[0m     prediction \u001b[39m=\u001b[39m predict(X, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    651\u001b[0m     \u001b[39mwith\u001b[39;00m lock:\n\u001b[0;32m    652\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\fasih\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:427\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    425\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    426\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[1;32m--> 427\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m    428\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    430\u001b[0m \u001b[39m# Classification\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rollTheWindow(orderData,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        region_hash  region_id\n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1\n",
      "1  f2c8c4bb99e6377d21de71275afd6cd2          2\n",
      "2  58c7a4888306d8ff3a641d1c0feccbe3          3\n",
      "3  b26a240205c852804ff8758628c0a86a          4\n",
      "4  4b9e4cf2fbdc8281b8a1f9f12b80ce4d          5\n"
     ]
    }
   ],
   "source": [
    "# read test data\n",
    "\n",
    "# read region Data\n",
    "regionTestData = pd.read_csv('./test_set/cluster_map/cluster_map', sep='\\t', names=['region_hash', 'region_id'],dtype={'region_hash': 'str', 'region_id': 'int'})\n",
    "print(regionTestData.head())\n",
    "#regionData.to_csv('regionData.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files read\n",
      "printing order data\n",
      "                           order_id                         driver_id  \\\n",
      "0  a51eaacf55aeeb106ac6cc429b8cd4f1  c34bbf688bd3008601bea47722023846   \n",
      "1  dbbf78e121305ff78578408fa80f0c3f  248955715350d5d9d2f0ee63c19760d9   \n",
      "2  87d9647097068af402aee1eec4efa2c1  248955715350d5d9d2f0ee63c19760d9   \n",
      "3  964f45562067302f486811fc24ec5f3f  756893197590002d87a87bfbee0f5f8b   \n",
      "4  d681c2fec2a3c4e1d55a073ee4a3a410  5d48fba0b0c71a0e776b5e30f042fe3e   \n",
      "\n",
      "                       passenger_id                 start_region_hash  \\\n",
      "0  62afaf3288e236b389af9cfdc5206415  62afaf3288e236b389af9cfdc5206415   \n",
      "1  d4ec2125aff74eded207d2d915ef682f  62afaf3288e236b389af9cfdc5206415   \n",
      "2  d4ec2125aff74eded207d2d915ef682f  62afaf3288e236b389af9cfdc5206415   \n",
      "3  929ec6c160e6f52c20a4217c7978f681  82cc4851f9e4faa4e54309f8bb73fd7c   \n",
      "4  91690261186ae5bee8f83808ea1e4a01  d4ec2125aff74eded207d2d915ef682f   \n",
      "\n",
      "                  time  \n",
      "0  2016-01-25 15:03:03  \n",
      "1  2016-01-25 19:19:10  \n",
      "2  2016-01-25 19:19:10  \n",
      "3  2016-01-25 21:16:19  \n",
      "4  2016-01-25 15:02:28  \n"
     ]
    }
   ],
   "source": [
    "# read order data\n",
    "dataTypes = {'order_id':'str', 'driver_id':'str', 'passenger_id':'str', 'start_region_hash':'str',  'time':'str'}\n",
    "orderDataPath = './test_set/order_data/'\n",
    "orderTestData = readMultipleData(orderDataPath,'test_order', ['order_id', 'driver_id', 'passenger_id', 'start_region_hash', 'time'], dataTypes,delimiter2=\",\")\n",
    "print(\"printing order data\")\n",
    "print(orderTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files read\n",
      "printing weather data\n",
      "                  time  weather  temperature  PM2.5\n",
      "0  2016-01-31 07:00:28        2          2.0   74.0\n",
      "1  2016-01-31 07:10:58        2          2.0   74.0\n",
      "2  2016-01-31 07:21:11        2          2.0   74.0\n",
      "3  2016-01-31 09:10:39        3          3.0   73.0\n",
      "4  2016-01-31 09:21:13        2          3.0   73.0\n"
     ]
    }
   ],
   "source": [
    "# read weather data\n",
    "dataTypes={'time':'str', 'weather':'int', 'temperature':'double', 'PM2.5':'double'}\n",
    "weatherTestDataPath = './test_set/weather_data/'\n",
    "weatherTestData = readMultipleData(weatherTestDataPath,'weather_data', ['time', 'weather', 'temperature', 'PM2.5'], dataTypes)\n",
    "print(\"printing weather data\")\n",
    "print(weatherTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date\n",
      "0        2         43  2016-01-31\n",
      "1        2         44  2016-01-31\n",
      "2        2         45  2016-01-31\n",
      "3        3         56  2016-01-31\n",
      "4        2         57  2016-01-31\n"
     ]
    }
   ],
   "source": [
    "#pre processing weather Test Data based on weather timeSlot \n",
    "weatherTestData['time_slot'] = weatherTestData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "weatherTestData['date'] = weatherTestData['time'].apply(extractDate)\n",
    "# weatherData['day_of_week'] = weatherData['time'].apply(extractDayOfWeek)\n",
    "weatherTestData = weatherTestData.drop(['temperature','PM2.5','time'], axis=1)\n",
    "print(weatherTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        region_hash  region_id  \\\n",
      "0  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "1  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "2  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "3  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "4  90c5a34f06ac86aee0fd70e2adce7d8a          1   \n",
      "\n",
      "                           order_id                         driver_id  \\\n",
      "0  99569e90c43b4c35430edc2b9a1f1923  26c9d645c9af54321d7ae08f9a106c3b   \n",
      "1  23e6ef541ca6ce42a2249c5ea5deafec  dae11494cab3404a2ec811f92b012932   \n",
      "2  3aeeb610b6219045ccfdd667d5629c39  dae11494cab3404a2ec811f92b012932   \n",
      "3  e39b165d871fee8a8528e5ff0e13dbed  3dcc34744e2c8943dc24ad6fb23b38ad   \n",
      "4  cacbb2f2c4373ebe908cfe7200e2bf59  3dcc34744e2c8943dc24ad6fb23b38ad   \n",
      "\n",
      "                  time  time_slot  day_of_week        date  \n",
      "0  2016-01-25 21:18:42        128            0  2016-01-25  \n",
      "1  2016-01-25 13:17:59         80            0  2016-01-25  \n",
      "2  2016-01-25 13:17:59         80            0  2016-01-25  \n",
      "3  2016-01-25 21:16:52        128            0  2016-01-25  \n",
      "4  2016-01-25 21:16:52        128            0  2016-01-25  \n"
     ]
    }
   ],
   "source": [
    "orderTestData = pd.merge(regionTestData,orderTestData, how='inner', right_on='start_region_hash', left_on='region_hash')\n",
    "orderTestData['time_slot'] = orderTestData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "orderTestData['day_of_week'] = orderTestData['time'].apply(extractDayOfWeek)\n",
    "orderTestData['date'] = orderTestData['time'].apply(extractDate)\n",
    "orderTestData = orderTestData.drop(['passenger_id','start_region_hash'], axis=1)\n",
    "print(orderTestData.head())\n",
    "# regionData=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  fe8870d68b93d37803e9ea3d49687ae2   \n",
      "1          1  0f39a932da47b57b4afbe2364fbc62ff   \n",
      "2          1  4fe3b9a2c9f821119a3c02effe5aed62   \n",
      "3          1  bf388aae3be6483fc2f5783cdb36908e   \n",
      "4          1  dc273c2e10c1a647d9d4a83f3f6a69e9   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \n",
      "0  a5a682526cda6fca705304d32b17ea51  2016-01-31 07:02:45            6  \n",
      "1  d7dd58906cf6a53e7093d4d1c5255943  2016-01-31 07:08:43            6  \n",
      "2  2b98ba78105e3fe9c8d1b8b2592eed32  2016-01-31 07:03:43            6  \n",
      "3  9a3dd9ab0707f7787369d68da66a5a9e  2016-01-31 07:05:23            6  \n",
      "4  1ece5e0aeed86e23e6d1fc01fae18519  2016-01-31 07:02:57            6  \n"
     ]
    }
   ],
   "source": [
    "mergedTestOrderData = pd.merge(weatherTestData,orderTestData, how=\"inner\", on=['date','time_slot'])\n",
    "print(mergedTestOrderData.head())\n",
    "# orderData.to_csv('orderData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderTestData=None\n",
    "orderTestData = mergedTestOrderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region_id  poi_count\n",
      "0          1     653376\n",
      "1          2     343537\n",
      "2          3      31125\n",
      "3          4     187829\n",
      "4          5      27888\n"
     ]
    }
   ],
   "source": [
    "# read POI Data\n",
    "poiDataStr = {\n",
    "    'region_hash':[],\n",
    "    'poi_class':[]\n",
    "}\n",
    "with open('./test_set/poi_data/poi_data','r') as fileToRead:\n",
    "    for line in fileToRead:\n",
    "        line = line.strip()\n",
    "        columns = line.split('\\t')\n",
    "        poiDataStr['region_hash'].append(columns[0])\n",
    "        remData = columns[1:]\n",
    "        poiDataStr['poi_class'].append(remData)\n",
    "        \n",
    "poiTestData = pd.DataFrame(poiDataStr,columns=['region_hash','poi_class'])\n",
    "poiTestData['poi_count'] = poiTestData['poi_class'].apply(extractNumberOfPOI)\n",
    "poiTestData = pd.merge(regionTestData,poiTestData, how='inner', on='region_hash')\n",
    "poiTestData = poiTestData.drop(['region_hash'], axis=1)\n",
    "poiTestData = poiTestData.drop(['poi_class'], axis=1)\n",
    "print(poiTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  fe8870d68b93d37803e9ea3d49687ae2   \n",
      "1          1  0f39a932da47b57b4afbe2364fbc62ff   \n",
      "2          1  4fe3b9a2c9f821119a3c02effe5aed62   \n",
      "3          1  bf388aae3be6483fc2f5783cdb36908e   \n",
      "4          1  dc273c2e10c1a647d9d4a83f3f6a69e9   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  a5a682526cda6fca705304d32b17ea51  2016-01-31 07:02:45            6   \n",
      "1  d7dd58906cf6a53e7093d4d1c5255943  2016-01-31 07:08:43            6   \n",
      "2  2b98ba78105e3fe9c8d1b8b2592eed32  2016-01-31 07:03:43            6   \n",
      "3  9a3dd9ab0707f7787369d68da66a5a9e  2016-01-31 07:05:23            6   \n",
      "4  1ece5e0aeed86e23e6d1fc01fae18519  2016-01-31 07:02:57            6   \n",
      "\n",
      "   poi_count  \n",
      "0     653376  \n",
      "1     653376  \n",
      "2     653376  \n",
      "3     653376  \n",
      "4     653376  \n"
     ]
    }
   ],
   "source": [
    "orderTestData = pd.merge(orderTestData,poiTestData, how=\"inner\", on='region_id')\n",
    "orderTestData = orderTestData.drop([\"poi_count_x\"],axis=1)\n",
    "orderTestData = orderTestData.rename(columns={\"poi_count_y\": \"poi_count\"})\n",
    "print(orderTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  fe8870d68b93d37803e9ea3d49687ae2   \n",
      "1          1  0f39a932da47b57b4afbe2364fbc62ff   \n",
      "2          1  4fe3b9a2c9f821119a3c02effe5aed62   \n",
      "3          1  bf388aae3be6483fc2f5783cdb36908e   \n",
      "4          1  dc273c2e10c1a647d9d4a83f3f6a69e9   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  a5a682526cda6fca705304d32b17ea51  2016-01-31 07:02:45            6   \n",
      "1  d7dd58906cf6a53e7093d4d1c5255943  2016-01-31 07:08:43            6   \n",
      "2  2b98ba78105e3fe9c8d1b8b2592eed32  2016-01-31 07:03:43            6   \n",
      "3  9a3dd9ab0707f7787369d68da66a5a9e  2016-01-31 07:05:23            6   \n",
      "4  1ece5e0aeed86e23e6d1fc01fae18519  2016-01-31 07:02:57            6   \n",
      "\n",
      "   poi_count  requests_x  requests_y  \n",
      "0     653376           1          37  \n",
      "1     653376           1          37  \n",
      "2     653376           1          37  \n",
      "3     653376           1          37  \n",
      "4     653376           1          37  \n"
     ]
    }
   ],
   "source": [
    "# print(mergedDataCSV)\n",
    "orderTestData['requests'] = 1\n",
    "# print(orderData.head())\n",
    "groupedTestMergedData = orderTestData.groupby(['region_id','time_slot','day_of_week','weather','poi_count'])['requests'].agg('sum').reset_index()\n",
    "# groupedMergedData = groupedMergedData.drop(['date','region_hash','order_id','driver_id','time'], axis=1)\n",
    "orderTestData = pd.merge(orderTestData,groupedTestMergedData, how='left' , on=['region_id','time_slot','day_of_week','weather','poi_count'])\n",
    "print(orderTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weather  time_slot        date                       region_hash  \\\n",
      "0        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "1        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "2        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "3        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "4        2         43  2016-01-31  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
      "\n",
      "   region_id                          order_id  \\\n",
      "0          1  fe8870d68b93d37803e9ea3d49687ae2   \n",
      "1          1  0f39a932da47b57b4afbe2364fbc62ff   \n",
      "2          1  4fe3b9a2c9f821119a3c02effe5aed62   \n",
      "3          1  bf388aae3be6483fc2f5783cdb36908e   \n",
      "4          1  dc273c2e10c1a647d9d4a83f3f6a69e9   \n",
      "\n",
      "                          driver_id                 time  day_of_week  \\\n",
      "0  a5a682526cda6fca705304d32b17ea51  2016-01-31 07:02:45            6   \n",
      "1  d7dd58906cf6a53e7093d4d1c5255943  2016-01-31 07:08:43            6   \n",
      "2  2b98ba78105e3fe9c8d1b8b2592eed32  2016-01-31 07:03:43            6   \n",
      "3  9a3dd9ab0707f7787369d68da66a5a9e  2016-01-31 07:05:23            6   \n",
      "4  1ece5e0aeed86e23e6d1fc01fae18519  2016-01-31 07:02:57            6   \n",
      "\n",
      "   poi_count  requests_x  requests  \n",
      "0     653376           1        37  \n",
      "1     653376           1        37  \n",
      "2     653376           1        37  \n",
      "3     653376           1        37  \n",
      "4     653376           1        37  \n"
     ]
    }
   ],
   "source": [
    "orderTestData = orderTestData.drop([\"requests_x\"], axis=1)\n",
    "orderTestData = orderTestData.rename(columns={\"requests_y\": \"requests\"})\n",
    "print(orderTestData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to calculate gap(i,j) = req(i,j) - supply(i,j)\n",
    "# # req(i,j) is for region i and timeslot j \n",
    "# # ith region will be from from start_region_hash and jth timeslot will be calculated from time\n",
    "# def getRegionID(regionHash):\n",
    "#     regionID = -1\n",
    "#     for i in range(len(regionData)):\n",
    "#         if regionHash == regionData['region_hash'][i]:\n",
    "#             regionID = regionData['region_id'][i]\n",
    "#     return regionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergedData = None # here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop order_id, driver_id, passenger_id, dest_region_hash\n",
    "# mergedData = orderData.drop(['order_id', 'passenger_id', 'dest_region_hash'], axis=1)\n",
    "# print(\"dropped order_id, passenger_id, dest_region_hash\")\n",
    "#  merge order data with region data on start_region_hash with region_hash\n",
    "# mergedData = pd.merge(regionData,mergedData, how='left', right_on='start_region_hash', left_on='region_hash')\n",
    "# print(\"merged order data and region data based on region\")\n",
    "\n",
    "# mergedData = mergedData.drop(['region_hash','start_region_hash'], axis=1)\n",
    "# print(\"dropped region_hash, start_region_hash\")\n",
    "# # reduce time to time slot and update time column\n",
    "# mergedData['time'] = mergedData['time'].apply(calculateTimeSlot,printValue=False)\n",
    "# print(\"reduced time to time slot 1 to 144\")\n",
    "# rename time to time_slot\n",
    "# mergedData.rename(columns={'time':'time_slot'}, inplace=True)\n",
    "# # append column for day of week into mergedData\n",
    "# mergedData['day_of_week'] = orderData['time'].apply(extractDayOfWeek)\n",
    "# print(\"appended day_of_week column to data\")\n",
    "# now we have mergedData with region_id, price, time, day_of_week\n",
    "# print(\"printing merged data\")\n",
    "# print(mergedData)\n",
    "\n",
    "# writing to mergedData.csv for quick access\n",
    "# orderData.to_csv('mergedData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mergedData.csv\n",
    "# mergedDataCSV = pd.read_csv('mergedData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mergedDataCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to get req(i,j) we can do that by counting the number of orders for region i and timeslot j\n",
    "# def getRequest(i,j): # i is region id and j is timeslot\n",
    "#     global orderData\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "#     requests = 0\n",
    "#     for row in range(len(orderData)):\n",
    "#         currentRegionID = getRegionID(orderData['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(orderData['time'][row],False)\n",
    "#         if currentRegionID == i and currentTimeSlot == j:\n",
    "#             requests += 1\n",
    "#         progressBarInit.update(1)\n",
    "#     progressBarInit.close()\n",
    "#     return requests\n",
    "\n",
    "# print(\"Printing request for 1st region and 1st timeslot\")\n",
    "# print(getRequest(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def dateToIndex(date):\n",
    "# #     index = 0\n",
    "    \n",
    "# #     return index\n",
    "\n",
    "# def getAllRequestAndSupply(): # need to filter by date \n",
    "#     global orderData\n",
    "#     global regionData\n",
    "#     global NUM_TIME_SLOTS\n",
    "#     global NUM_DAYS_IN_DATA\n",
    "#     numberOfRegions = len(regionData)\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "#     # 3D requests array requests[i][j][k] is number of requests --> date i ,region j, timeslot k\n",
    "#     # requests = [[[0 for k in range(NUM_TIME_SLOTS)] for j in range(numberOfRegions)] for i in range(NUM_DAYS_IN_DATA)]\n",
    "#     # supply = [[[0 for k in range(NUM_TIME_SLOTS)] for j in range(numberOfRegions)] for i in range(NUM_DAYS_IN_DATA)]\n",
    "#     requests = [[0 for j in range(NUM_TIME_SLOTS)] for i in range(numberOfRegions)]\n",
    "#     supply = [[0 for j in range(NUM_TIME_SLOTS)] for i in range(numberOfRegions)]\n",
    "#     for row in range(len(orderData)):\n",
    "#         currentRegionID = getRegionID(orderData['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(orderData['time'][row],False)\n",
    "#         # date = orderData['time'][row].split(' ')[0]\n",
    "        \n",
    "#         if currentRegionID < 0:\n",
    "#             print(f\"Region not found for {orderData['start_region_hash'][row]}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot < 0:\n",
    "#             print(f\"Time slot not found for {orderData['time'][row]}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentRegionID > numberOfRegions:\n",
    "#             print(f\"Region id {currentRegionID} is greater than number of regions {numberOfRegions}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot > NUM_TIME_SLOTS:\n",
    "#             print(f\"Time slot {currentTimeSlot} is greater than number of time slots {NUM_TIME_SLOTS}\")\n",
    "#             print(f\"Time: {orderData['time'][row]}\")\n",
    "#             print(f\"Row: {row}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         if currentTimeSlot == 0:\n",
    "#             print(f\"Time slot is 0 for {orderData['time'][row]}\")\n",
    "#             print(f\"Row: {row}\")\n",
    "#             continue\n",
    "#             # return (None,None)\n",
    "#         # requests[currentDate][currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         requests[currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         if type(orderData['driver_id'][row]) == str:\n",
    "#             supply[currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#             # supply[currentDate][currentRegionID-1][currentTimeSlot-1] += 1\n",
    "#         progressBarInit.update(1)\n",
    "#     progressBarInit.close()\n",
    "#     return (requests,supply)\n",
    "\n",
    "# print(\"Printing request and supply regions d(i) and timeslots t(j)\")\n",
    "# (request,supply) = getAllRequestAndSupply()\n",
    "# print(request)\n",
    "# print(supply) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npRequest = np.array(request)\n",
    "# npSupply = np.array(supply)\n",
    "# np.savetxt('request.csv', npRequest, delimiter=',')\n",
    "# np.savetxt('supply.csv', npSupply, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to get req(i,j) we can do that by counting the number of orders for region i and timeslot j\n",
    "# # concurrentI =0\n",
    "# # concurrentJ =0\n",
    "# def getRequestMulti(data, i, j,lowerIndex,upperIndex):\n",
    "#     # (orderData, i, j,lowerIndex,upperIndex) = arguments\n",
    "#     numberOfIterations = upperIndex - lowerIndex\n",
    "#     currentPID = mp.current_process()._identity[0]-1\n",
    "#     # logging.info(f\"process {currentPID}\")\n",
    "#     print(f\"Number of lines of data: {numberOfIterations} for process {currentPID}\")\n",
    "#     # progressBarInit = tqdm(total=numberOfIterations, desc=f\"Calculating requests {currentPID}\", unit=\" lines\")\n",
    "#     lowerIndex = lowerIndex[currentPID]\n",
    "#     upperIndex = upperIndex[currentPID]\n",
    "#     requests = 0\n",
    "#     for row in range(lowerIndex,upperIndex):\n",
    "#         currentRegionID = getRegionID(data['start_region_hash'][row])\n",
    "#         currentTimeSlot = calculateTimeSlot(data['time'][row],False)\n",
    "#         if currentRegionID == i and currentTimeSlot == j:\n",
    "#             requests += 1\n",
    "#         # progressBarInit.update(1)\n",
    "#     # progressBarInit.close()\n",
    "#     return requests\n",
    "\n",
    "# def getRequestHelper(i,j): # i is region id and j is timeslot\n",
    "#     global orderData\n",
    "#     # global concurrentI\n",
    "#     # global concurrentJ\n",
    "#     # concurrentJ = j\n",
    "#     # concurrentI = i\n",
    "#     numberOfIterations = len(orderData)\n",
    "#     # logging.basicConfig(level=logging.INFO,filename='worker.log', filemode='w')\n",
    "#     # console_handler = logging.StreamHandler()\n",
    "#     # logging.getLogger().addHandler(console_handler)\n",
    "#     # print(f\"Number of lines of data: {numberOfIterations}\")\n",
    "#     # progressBarInit = tqdm(total=numberOfIterations, desc=\"Calculating requests\", unit=\" lines\")\n",
    "    \n",
    "#     numberOfProcessesToRun = mp.cpu_count()\n",
    "#     print(f\"CPUs: {numberOfProcessesToRun}\")\n",
    "#     multiProcessingPool = mp.Pool(numberOfProcessesToRun)\n",
    "#     upperIndex = []\n",
    "#     lowerIndex = []\n",
    "#     for i in range(numberOfProcessesToRun):\n",
    "#         lowerval = i*numberOfIterations//numberOfProcessesToRun\n",
    "#         upperVal = (i+1)*numberOfIterations//numberOfProcessesToRun\n",
    "#         lowerIndex.append(lowerval)\n",
    "#         upperIndex.append(upperVal)\n",
    "#     print(\"Here\")\n",
    "#     # argumentsToPass = (orderData, i, j,lowerIndex, upperIndex)\n",
    "#     requests = multiProcessingPool.starmap(getRequestMulti, [(orderData, i, j,lowerIndex, upperIndex)])\n",
    "#     requests = sum(requests)\n",
    "#     multiProcessingPool.close()\n",
    "#     multiProcessingPool.join()\n",
    "#     return requests\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Printing request for 1st region and 1st timeslot\")\n",
    "# print(getRequestHelper(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
